{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec6d37f-773e-4e19-904e-a0bac7396697",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys, time, os, math\n",
    "import string\n",
    "sys.path.append('/home/groups/ZuckermanLab/jalim/instalLocal/celltraj/celltraj')\n",
    "import trajCellPoseSr\n",
    "import h5py\n",
    "import scipy\n",
    "import subprocess\n",
    "import umap\n",
    "#from deeptime.clustering import KMeans\n",
    "from csaps import csaps\n",
    "from joblib import dump, load\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788ffc3b-9598-4f03-99dd-833dcd2b3aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trajectory Length for morphodynamical trajectory analysis\n",
    "trajl = 40\n",
    "#trajl = int(sys.argv[1])\n",
    "#if trajl is None:\n",
    "#  print(\"Enter trajectory snippet length for morphodynamical analysis\")\n",
    "#  sys.exit(0)\n",
    "\n",
    "#os.environ['OMP_NUM_THREADS'] = '1'; os.environ['MKL_NUM_THREADS'] = '1'\n",
    "\n",
    "today = date.today()\n",
    "date2day = today.strftime(\"%b%d-%Y\")\n",
    "sysName = 'LI204601_P'\n",
    "figid = sysName+'_tlen'+str(trajl)+'_'+date2day\n",
    "conditions = ['A1','A2','A3','A4','A5','B1','B2','B3','B4','B5','C1','C2','C3'] # LIGANDS (CONDITIONS)\n",
    "tmSet = ['OSM1','EGF1','EGF+TGFB1','TGFB1','PBS1','OSM2','EGF2','EGF+TGFB2','TGFB2','PBS2',\n",
    "         'OSM+EGF+TGFB','OSM+EGF','OSM+TGFB']\n",
    "nRepConds = 5 # Number of models (conditions) that are replicas \n",
    "nConditions = len(tmSet) # Total number of Ligand Conditions\n",
    "# Indices for the ligands = 13\n",
    "inds_tmSet = [i for i in range(nConditions)]\n",
    "inds_tmSet = np.array(inds_tmSet).astype(int)\n",
    "nfovs = 4\n",
    "fovs = [i for i in range(1, nfovs + 1)]\n",
    "fovs = np.array(fovs).astype(int)\n",
    "dateSet = ['']\n",
    "pathSet = ['/home/groups/ZuckermanLab/jalim/LI204601_INCUCYTE/segsCellPose/dynaMorph']\n",
    "imagingSet = [0 for i in range(nConditions)]\n",
    "modelList = [None]*(nfovs*(nConditions))\n",
    "modelList_conditions = np.zeros(nfovs*(nConditions)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f75315-9fc0-449a-b0df-6ba441db64f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "icond = 0\n",
    "for cond in conditions:\n",
    "    for fov in fovs:\n",
    "        modelList_conditions[i] = icond\n",
    "        modelName = sysName+'_'+cond+'_'+str(fov)\n",
    "        # Get the name of .obj file as a \"string\", including its path\n",
    "        modelList[i] = pathSet[imagingSet[icond]]+'/'+modelName+dateSet[imagingSet[icond]]\n",
    "        #print(\"Model names = \", modelList[i])\n",
    "        i = i + 1\n",
    "    icond = icond + 1\n",
    "\n",
    "nmodels = int(i)\n",
    "indgood_models = np.array([]).astype(int)\n",
    "model_objects = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de257502-acf7-4b14-9d91-ee3928ebc1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(nmodels):\n",
    "    try:\n",
    "        objFile = modelList[i]+'.joblib'\n",
    "        with open(objFile, 'rb') as fp:\n",
    "            # Load objects from the file \n",
    "            linSet, Xf, Xf_com, cells_frameSet, cells_indSet, Trajectories, cells_imgfileSet, cells_indcmskSet  = load(fp)\n",
    "            # Assign objects of each model separately to call later by index \"i\" and object name\n",
    "            model_objects[i] = {'linSet': linSet,\n",
    "                                'Xf': Xf,\n",
    "                                'Xf_com': Xf_com,\n",
    "                                'cells_frameSet': cells_frameSet,\n",
    "                                'cells_indSet': cells_indSet,\n",
    "                                'Trajectories': Trajectories,\n",
    "                                'cells_imgfileSet': cells_imgfileSet,\n",
    "                                'cells_indcmskSet': cells_indcmskSet}\n",
    "            print('loaded '+'.../'+objFile[32:]+' with '+str(model_objects[i]['cells_indSet'].size)+' cells')\n",
    "            test = len(model_objects[i]['linSet'])\n",
    "            indgood_models = np.append(indgood_models, i)\n",
    "    except:\n",
    "        print(\"Error in reading data from .joblib files\")\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c67a64-505c-453f-87da-0eb9b158916c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nframes = 193 # 193 Frames -->  each of 15 mins = 48 hrs\n",
    "# Create arrays for (TIFF) image files and frames (dumped @ 15 minutes) \n",
    "imgfileList = np.array([])\n",
    "imgfileList = np.append(imgfileList, 0)\n",
    "start_frame = 0\n",
    "end_frame = nframes\n",
    "imgfileSet = imgfileList.copy()\n",
    "frameSet = start_frame*np.ones_like(imgfileSet)\n",
    "for i in range(start_frame+1, end_frame+1):\n",
    "    imgfileSet = np.append(imgfileSet, imgfileList)\n",
    "    frameSet = np.append(frameSet, i*np.ones_like(imgfileList))\n",
    "\n",
    "imgfileSet = imgfileSet.astype(int)\n",
    "frameSet = frameSet.astype(int)\n",
    "cellnumber_stdSet = np.ones(nmodels)*np.inf\n",
    "# range of frame indices where cell numbers are higher: ~70-98%\n",
    "sframe = 70.*nframes/100.; sframe = math.ceil(sframe)\n",
    "eframe = 98.5*nframes/100.; eframe = math.ceil(eframe)\n",
    "cellnumber_frames = np.arange(sframe, eframe).astype(int)\n",
    "cellnumber_std_cut = .50 # This was set to 0.10 by Jeremy \n",
    "frames = np.arange(nframes)\n",
    "# Abscissas at which smoothing will be done using CSAPS package\n",
    "abSmooth = np.linspace(frames[0], frames[-1], 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f4dd5d-4db3-4abc-9993-e7ae4da3a0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.clf()\n",
    "#plt.figure(figsize = (8, 7))\n",
    "\n",
    "with open('cellNumbers.dat', 'w', encoding = 'utf-8') as fp: # PRINT cell numbers in a file for each model\n",
    "    for i in indgood_models:\n",
    "        ncells = np.zeros(nframes)\n",
    "        ncells_smooth = np.zeros_like(ncells)\n",
    "        cell_indCmskSet = np.array([]) # Array of masked cell indices\n",
    "        for iS in range(nframes):\n",
    "            ncells[iS] = np.sum(model_objects[i]['cells_frameSet'] == iS)\n",
    "            cell_indCmskSet = np.append(cell_indCmskSet, iS*np.ones(int(ncells[iS])))\n",
    "            fp.write(str(ncells[iS])+\"\\t\")\n",
    "        fp.write(\"\\n\")\n",
    "        cell_indCmskSet = cell_indCmskSet.astype(int)\n",
    "        model_objects[i]['cells_indcmskSet'] = cell_indCmskSet\n",
    "        model_objects[i]['cells_imgfileSet'] = cell_indCmskSet\n",
    "        #print(\"Shape of cell masks indices =\", model_objects[i]['cells_indcmskSet'].shape)\n",
    "        # Cubic Spline Approximation (CSAPS) to smoothen the data\n",
    "        splfov = csaps(frames, ncells/ncells[0], abSmooth, smooth = 0.98) # Scaled by ncells[0] to avoid large numbers\n",
    "        ncells_smooth = splfov*ncells[0] # smoothened cell numbers reverse scaled back to original\n",
    "        cellnumber_std = np.std(ncells[cellnumber_frames] \n",
    "                                - ncells_smooth[cellnumber_frames])/np.mean(ncells[cellnumber_frames])\n",
    "        cellnumber_stdSet[i] = cellnumber_std # Standard Deviation in Cell Numbers\n",
    "        #print(\"cellnumber_stdSet[\",i,\"] = \", cellnumber_std)\n",
    "        # Plot number of normalized number of cells vs frame number for each Model\n",
    "        #plt.plot(ncells/ncells[0], color = colModels[i], label = capModels[i]);\n",
    "        #plt.plot(ncells, color = colModels[i], label = capModels[i]);plt.pause(.5) \n",
    "        #plt.plot(ncells/ncells[0]); plt.pause(.5) \n",
    "\n",
    "#plt.xlabel('Frame Number')\n",
    "#plt.ylabel('Normalized Cell Numbers')\n",
    "#plt.legend(loc='best')\n",
    "#plt.tight_layout()\n",
    "#plt.savefig('cellNumbers_'+figid+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86efc8f1-c3de-44da-b4a2-11fe79b7f7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "indhigh_std = np.where(cellnumber_stdSet > cellnumber_std_cut)[0]\n",
    "indgood_models = np.setdiff1d(indgood_models, indhigh_std)\n",
    "#print(\"Indices of high SD models = \", indhigh_std); print(\"Indices of good models = \", indgood_models); sys.exit(0)\n",
    "print(\"Number of Good Models = \", len(indgood_models))\n",
    "\n",
    "num_trajModSet = len(tmSet) # Total number of trajectory (models) conditions including replicas\n",
    "inds_tmSet_models = np.zeros(nmodels).astype(int)\n",
    "inds_imagingSet_models = np.zeros(nmodels).astype(int)\n",
    "i = 0\n",
    "icond = 0\n",
    "for cond in conditions:\n",
    "    for fov in fovs:\n",
    "        inds_tmSet_models[i] = inds_tmSet[icond]\n",
    "        inds_imagingSet_models[i] = imagingSet[icond]\n",
    "        i = i + 1\n",
    "    icond = icond + 1\n",
    "\n",
    "# just replace with zeros for now? Not sure best..\n",
    "for i in indgood_models:\n",
    "    if inds_imagingSet_models[i] == 0:\n",
    "        model_objects[i]['Xf'][np.isnan(model_objects[i]['Xf'])] = 0.0\n",
    "\n",
    "nfeat_com = 3\n",
    "Xf_com0 = np.zeros((0, nfeat_com))\n",
    "for i in indgood_models:\n",
    "    if inds_imagingSet_models[i] == 0:\n",
    "        Xf_com0 = np.append(Xf_com0, model_objects[i]['Xf_com'], axis=0)\n",
    "\n",
    "av_dx = np.nanmean(Xf_com0[:, 0])\n",
    "std_dx = np.nanstd(Xf_com0[:, 0])\n",
    "for i in indgood_models:\n",
    "    model_objects[i]['Xf_com'][:, 0] = (model_objects[i]['Xf_com'][:, 0] - av_dx)/std_dx\n",
    "\n",
    "nfeat = model_objects[indgood_models[0]]['Xf'].shape[1]\n",
    "Xf0 = np.zeros((0, nfeat))\n",
    "indtreatment = np.array([])\n",
    "indcellSet = np.array([])\n",
    "for i in indgood_models:\n",
    "    if inds_imagingSet_models[i] == 0:\n",
    "        Xf0 = np.append(Xf0, model_objects[i]['Xf'], axis=0)\n",
    "        indtreatment = np.append(indtreatment, i*np.ones(model_objects[i]['Xf'].shape[0]))\n",
    "        indcellSet = np.append(indcellSet, model_objects[i]['cells_indSet'])\n",
    "\n",
    "indtreatment = indtreatment.astype(int)\n",
    "indcellSet = indcellSet.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad77c60-a100-45b7-82e5-8c67aeb6065b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will use the sklearn package (intended for ease of use over performance/scalability)\n",
    "from sklearn.decomposition import PCA \n",
    "# n_components specifies the number of principal components to extract from the covariance matrix\n",
    "#pca = PCA(n_components = 3)\n",
    "varCutOff = 0.99\n",
    "#@@@@@@ Variance Cut Offs and their corresponding features after dimensional reduction using PCA @@@@@@\n",
    "#varCutOffs = [0.95, 0.96, 0.965, 0.97, 0.975, 0.98, 0.985, 0.99, 0.992, 0.994, 0.995, 0.996, 0.997, 0.998, 0.999]\n",
    "#nFeatures = [5, 6, 6, 7, 7, 8, 9, 10, 11, 13, 14, 16, 17, 20, 27]\n",
    "#for varCutOff in varCutOffs:\n",
    "pca = PCA(n_components = varCutOff)\n",
    "# builds the covariance matrix, fit the PCs, and transforms the data into the PCA representation\n",
    "Xpca = pca.fit_transform(Xf0) \n",
    "print(\"Number of cell features used after dimensional reduction: \",Xpca.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9677e187",
   "metadata": {},
   "outputs": [],
   "source": [
    "wctm = trajCellPoseSr.cellPoseTraj()  \n",
    "wctm.Xpca = Xpca\n",
    "\n",
    "for i in indgood_models:\n",
    "    if inds_imagingSet_models[i] == 0:\n",
    "        indsf = np.where(indtreatment == i)[0]\n",
    "        model_objects[i]['Xpca'] = Xpca[indsf, :]\n",
    "\n",
    "indgood_models = indgood_models[np.where(inds_imagingSet_models[indgood_models] == 0)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0f246a-71eb-4e68-ad7c-439801a23163",
   "metadata": {},
   "outputs": [],
   "source": [
    "self = wctm\n",
    "wctm.trajl = trajl\n",
    "self.imgfileSet = imgfileSet\n",
    "self.frameSet = frameSet\n",
    "all_trajSet = [None]*nmodels\n",
    "cells_indcmskSet = []\n",
    "for i in indgood_models:\n",
    "    self.trajectories = model_objects[i]['Trajectories']\n",
    "    self.cells_imgfileSet = model_objects[i]['cells_imgfileSet']\n",
    "    self.cells_frameSet = model_objects[i]['cells_frameSet']\n",
    "    self.cells_indSet = model_objects[i]['cells_indSet']\n",
    "    self.cells_indcmskSet = model_objects[i]['cells_indcmskSet']\n",
    "    self.linSet = model_objects[i]['linSet']\n",
    "    self.get_unique_trajectories() # Due to embedded trajectories \n",
    "    all_trajSet[i] = self.trajectories.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e84dd7-6fba-4e32-95f5-1ceff5b5b7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing PCA'ed features at a desired trajectory snippet length, i.e., \"trajl\"\n",
    "Xpcat = np.zeros((0, pca.n_components_*trajl + nfeat_com*trajl))\n",
    "indtreatment_traj = np.array([])\n",
    "indstack_traj = np.array([])\n",
    "indframes_traj = np.array([])\n",
    "cellinds0_traj = np.array([])\n",
    "cellinds1_traj = np.array([])\n",
    "cb_ratio_traj = np.array([])\n",
    "for i in indgood_models:\n",
    "    print(\"building trajectory data for model\", i ,\"...\")\n",
    "    self.trajectories = all_trajSet[i].copy()\n",
    "    model_objects[i]['Trajectories'] = self.trajectories\n",
    "    model_objects[i]['trajl'] = trajl\n",
    "    model_objects[i]['traj'] = self.get_traj_segments(trajl) \n",
    "    data = model_objects[i]['Xpca'][model_objects[i]['traj'], :]\n",
    "    datacom = model_objects[i]['Xf_com'][model_objects[i]['traj'], :]\n",
    "    data = data.reshape(model_objects[i]['traj'].shape[0], model_objects[i]['Xpca'].shape[1]*trajl)\n",
    "    datacom = datacom.reshape(model_objects[i]['traj'].shape[0], model_objects[i]['Xf_com'].shape[1]*trajl)\n",
    "    data = np.append(data, datacom, axis=1)\n",
    "    indgood = np.where(np.sum(np.isnan(data), axis=1) == 0)[0]\n",
    "    data = data[indgood, :]\n",
    "    model_objects[i]['traj'] = model_objects[i]['traj'][indgood, :]\n",
    "    Xpcat = np.append(Xpcat, data, axis = 0)\n",
    "    indtreatment_traj = np.append(indtreatment_traj, i*np.ones(data.shape[0]))\n",
    "    indstacks = model_objects[i]['cells_imgfileSet'][model_objects[i]['traj'][:, 0]]\n",
    "    indstack_traj = np.append(indstack_traj, indstacks)\n",
    "    indframes = model_objects[i]['cells_frameSet'][model_objects[i]['traj'][:, 0]]\n",
    "    indframes_traj = np.append(indframes_traj, indframes)\n",
    "    cellinds0 = model_objects[i]['traj'][:, 0]\n",
    "    cellinds0_traj = np.append(cellinds0_traj, cellinds0)\n",
    "    cellinds1 = model_objects[i]['traj'][:, -1]\n",
    "    cellinds1_traj = np.append(cellinds1_traj, cellinds1)\n",
    "    cb_ratio_traj = np.append(cb_ratio_traj, model_objects[i]['Xf'][cellinds1, 77])\n",
    "\n",
    "cellinds0_traj = cellinds0_traj.astype(int)\n",
    "cellinds1_traj = cellinds1_traj.astype(int)\n",
    "print(\"Shape of Xpcat: \",Xpcat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3df8a2-4e9f-4e6f-a4ba-8d146ec5d676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply UMAP on PCA'ed features of cell trajectories\n",
    "get_embedding = False\n",
    "neigen = 2\n",
    "if get_embedding:\n",
    "    reducer = umap.UMAP(n_neighbors = 200, min_dist = 0.1,\n",
    "                        n_components = neigen, metric = 'euclidean')\n",
    "    trans = reducer.fit(Xpcat)\n",
    "    embedTraj_feat = trans.embedding_\n",
    "    indst = np.arange(embedTraj_feat.shape[0]).astype(int)\n",
    "    wctm.Xtraj = embedTraj_feat.copy()\n",
    "    wctm.indst = indst.copy()\n",
    "    dump(embedTraj_feat, sysName+'_trajl'+str(trajl)+'_d2embedding_'+date2day+'.joblib')\n",
    "else:\n",
    "    embedTraj_feat = load(sysName+'_trajl'+str(trajl)+'_d2embedding_'+date2day+'.joblib')\n",
    "\n",
    "print(\"Applied UMAP for dimensional reduction @ 2D on trajectory embedding data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c19a21-c40e-434f-8978-d78cea4387b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "inds_conditions = [None]*num_trajModSet\n",
    "for imf in range(num_trajModSet):\n",
    "    indmodels = np.intersect1d(indgood_models, np.where(inds_tmSet_models == imf)[0])\n",
    "    indstm = np.array([])\n",
    "    for imodel in indmodels:\n",
    "        indtm = np.where(indtreatment_traj == imodel)\n",
    "        indstm = np.append(indstm, indtm)\n",
    "    inds_conditions[imf] = indstm.astype(int).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c6cfb9-c5c2-4ee9-a6af-4bb97b9bd196",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### Clustering using KMeans from sklearn OR deeptime OR pyemma.coordinates #####################\n",
    "Xpcat_ = Xpcat.copy()\n",
    "n_clusters = 200\n",
    "# cluster trajectories and store in 'clusters' that have attributes like cluster_centers_, inertia, ...\n",
    "from sklearn.cluster import KMeans\n",
    "clusters_skl = KMeans(n_clusters = n_clusters, init='k-means++',\n",
    "                      max_iter = 1000, random_state = 0).fit(Xpcat_)\n",
    "centers_skl = clusters_skl.cluster_centers_\n",
    "\n",
    "import pyemma.coordinates as coor\n",
    "#clusters = coor.cluster_kmeans(embedTraj_feat, k = n_clusters, metric = 'euclidean',\n",
    "clusters = coor.cluster_kmeans(Xpcat, k = n_clusters, metric = 'euclidean',\n",
    "                               init_strategy = 'kmeans++', max_iter = 1000,\n",
    "                               clustercenters = centers_skl, keep_data = True)\n",
    "# Here, using cluster centers from sklearn's KMeans \n",
    "wctm.clusterst = clusters \n",
    "print(\"Clustering of embedded trajectories is Done!\")\n",
    "neigen = Xpcat.shape[1] # When using the PCA'ed featured trajectories\n",
    "#neigen = embedTraj_feat.shape[1] # When using UMAP'ed after PCA'ed features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3b31b4-16d3-4401-bfe2-998c2c4d2b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################## Start Tracking of Single Cell Trajectories  #########################\n",
    "knn = 50\n",
    "dxs = np.zeros((nmodels, n_clusters, neigen))\n",
    "x0set = np.zeros((0, neigen))\n",
    "x1set = np.zeros((0, neigen))\n",
    "inds_trajsteps_models = np.array([]).astype(int)\n",
    "\n",
    "for i in indgood_models:\n",
    "    print('getting flows from model: '+str(i))\n",
    "    indstm = np.where(indtreatment_traj == i)[0]\n",
    "    if indstm.size > 0:\n",
    "        #embedTraj = embedTraj_feat[indstm, 0:neigen]\n",
    "        embedTraj = Xpcat[indstm, 0:neigen]\n",
    "        model_objects[i]['Xtraj'] = embedTraj\n",
    "        indstm_model = indstm - np.min(indstm) #index in model\n",
    "        traj = model_objects[i]['traj'][indstm_model, :]\n",
    "        Xtraj = model_objects[i]['Xtraj'][indstm_model, :]\n",
    "        # nlag = 1 --> trajectories are recorded at same time step, i.e., @ 15 mins in this Dataset\n",
    "        self.trajectories = model_objects[i]['Trajectories']\n",
    "        self.cells_imgfileSet = model_objects[i]['cells_imgfileSet']\n",
    "        self.cells_frameSet = model_objects[i]['cells_frameSet']\n",
    "        self.cells_indSet = model_objects[i]['cells_indSet']\n",
    "        self.cells_indcmskSet = model_objects[i]['cells_indcmskSet']\n",
    "        self.linSet = model_objects[i]['linSet']\n",
    "        nlag = 1\n",
    "        inds_model = np.arange(self.cells_indSet.size).astype(int)\n",
    "        inds = inds_model\n",
    "        get_trajectories = True\n",
    "        if get_trajectories:\n",
    "            self.get_unique_trajectories(cell_inds = inds, verbose = False)\n",
    "        trajp1 = self.get_traj_segments(self.trajl + nlag)\n",
    "        #sys.stdout.write('Shape of trajectory segments for models '+str(trajp1.shape)+'\\n')\n",
    "        inds_nlag = np.flipud(np.arange(self.trajl + nlag - 1, -1, -nlag)).astype(int) # keep indices every nlag\n",
    "        trajp1 = trajp1[:, inds_nlag]\n",
    "        ntraj = trajp1.shape[0]\n",
    "        #neigen = embedTraj_feat.shape[1]\n",
    "        neigen = Xpcat.shape[1]\n",
    "        x0 = np.zeros((0, neigen))\n",
    "        x1 = np.zeros((0, neigen))\n",
    "        inds_trajp1 = np.zeros((0, 2)).astype(int)\n",
    "        for itraj in range(ntraj):\n",
    "            test0 = trajp1[itraj, 0:-1]\n",
    "            test1 = trajp1[itraj, 1:]\n",
    "            res0 = (traj[:, None] == test0[np.newaxis, :]).all(-1).any(-1)\n",
    "            res1 = (traj[:, None] == test1[np.newaxis, :]).all(-1).any(-1)\n",
    "            if (np.sum(res0) == 1) and (np.sum(res1) == 1):\n",
    "                indt0 = np.where(res0)[0][0]\n",
    "                indt1 = np.where(res1)[0][0]\n",
    "                #x0 = np.append(x0, np.array([embedTraj_feat[indt0, :]]), axis=0)\n",
    "                #x1 = np.append(x1, np.array([embedTraj_feat[indt1, :]]), axis=0)\n",
    "                x0 = np.append(x0, np.array([Xpcat[indt0, :]]), axis=0)\n",
    "                x1 = np.append(x1, np.array([Xpcat[indt1, :]]), axis=0)\n",
    "                inds_trajp1 = np.append(inds_trajp1, np.array([[indt0, indt1]]), axis=0)\n",
    "            if itraj%100 == 0:\n",
    "                sys.stdout.write('matching up trajectory '+str(itraj)+'\\n')\n",
    "        \n",
    "        model_objects[i]['Xtraj0'] = x0\n",
    "        model_objects[i]['Xtraj1'] = x1\n",
    "        model_objects[i]['inds_trajp1'] = inds_trajp1\n",
    "        x0set = np.append(x0set, x0, axis=0)\n",
    "        x1set = np.append(x1set, x1, axis=0)\n",
    "        inds_trajsteps_models = np.append(inds_trajsteps_models, np.ones(x0.shape[0])*i)\n",
    "        dx = x1 - x0 # Measure the difference in morphological properties at two different times\n",
    "        #print(\"No of trajectories in model \",i,\"are \",ntraj, \"shape of dx for model \",i,\"is \",dx.shape)\n",
    "        for iclust in range(n_clusters):\n",
    "            xc = np.array([clusters.clustercenters[iclust, :]])\n",
    "            #################### Get Density matrix ####################\n",
    "            ind_trajectory = model_objects[i]['inds_trajp1'][:, -1] # \n",
    "            xc_0 = model_objects[i]['Xtraj'][ind_trajectory, :] \n",
    "            dmatr = wctm.get_dmat(xc_0, xc) #get closest cells to cluster center\n",
    "            indr = np.argsort(dmatr[:, 0])\n",
    "            indr = indr[0:knn]\n",
    "            cell_inds_t = model_objects[i]['inds_trajp1'][indr, -1]\n",
    "            cellindsr = model_objects[i]['traj'][cell_inds_t, -1]\n",
    "            dxs[i, iclust, :] = np.mean(dx[indr, :], axis=0)\n",
    "dxsav = np.mean(dxs, axis=0) \n",
    "######################## End Tracking of Single Cell Trajectories  #########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774cac3f-03a8-4dc5-a3ec-c618ac8b385d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cumulative distribution of UMAP'ed trajectories \n",
    "def get_cdist2d(prob1):\n",
    "    nx = prob1.shape[0]\n",
    "    ny = prob1.shape[1]\n",
    "    prob1 = prob1/np.sum(prob1)\n",
    "    prob1 = prob1.flatten()\n",
    "    indprob1 = np.argsort(prob1)\n",
    "    probc1 = np.zeros_like(prob1)\n",
    "    probc1[indprob1] = np.cumsum(prob1[indprob1])\n",
    "    probc1 = 1. - probc1\n",
    "    probc1 = probc1.reshape((nx, ny))\n",
    "    return probc1\n",
    "\n",
    "def colorbar(mappable):\n",
    "    from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "    last_axes = plt.gca()\n",
    "    ax = mappable.axes\n",
    "    fig = ax.figure\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "    cbar = fig.colorbar(mappable, cax=cax)\n",
    "    plt.sca(last_axes)\n",
    "    return cbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708cebe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbins = 20\n",
    "######## Frames for time window ########\n",
    "fl = 72 # 18 hrs\n",
    "fu = 120 # 30 hrs\n",
    "#fu = nframes  \n",
    "\n",
    "indtreatment_traj = indtreatment_traj.astype(int)\n",
    "inds_imagingSet_traj = inds_imagingSet_models[indtreatment_traj]\n",
    "\n",
    "indstw = np.where(np.logical_and(indframes_traj < fu, indframes_traj > fl))[0]\n",
    "indscc = np.where(cb_ratio_traj < np.inf)[0]\n",
    "indstw = np.intersect1d(indstw, indscc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54abb147-7f1f-4e2b-ba9c-395ae70ea43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot embedded probabilities for each condition and the cumulative one \n",
    "probSet = [None]*nmodels\n",
    "plt.figure(figsize = (9, 9))\n",
    "nRows_subplt = 5; nCols_subplt = 3\n",
    "plt.subplot(nRows_subplt, nCols_subplt, 1) # Combined cumulative probability distribution over all models\n",
    "prob1, xedges1, yedges1 = np.histogram2d(embedTraj_feat[indstw, 0], embedTraj_feat[indstw, 1],\n",
    "                                         bins=nbins, density=True)\n",
    "prob1c = get_cdist2d(prob1)\n",
    "xx, yy = np.meshgrid(.5*xedges1[1:] + .5*xedges1[0:-1], .5*yedges1[1:] + .5*yedges1[0:-1])\n",
    "levels = np.linspace(0, 1, 21)\n",
    "cs = plt.contourf(xx, yy, prob1c.T, levels=levels, cmap=plt.cm.jet_r)\n",
    "cbar = colorbar(cs)\n",
    "cbar.set_label('cumulative probability')\n",
    "plt.title('combined cumulative distribution', fontsize = 10)\n",
    "plt.axis('off')\n",
    "for imf in range(num_trajModSet):\n",
    "    tm = tmSet[imf] # Trajectory model\n",
    "    indstm = inds_conditions[imf]\n",
    "    indstwm = np.intersect1d(indstm, indstw)\n",
    "    indstwm = np.intersect1d(indstwm, indscc)\n",
    "    prob, xedges2, yedges2 = np.histogram2d(embedTraj_feat[indstwm, 0], embedTraj_feat[indstwm, 1],\n",
    "                                            bins=[xedges1, yedges1], density=True)\n",
    "    #prob = prob/np.sum(prob)\n",
    "    probc = get_cdist2d(prob)\n",
    "    probSet[imf] = prob.copy()\n",
    "    plt.subplot(nRows_subplt, nCols_subplt, imf + 2) # Probability distribution of each model \n",
    "    #levels = np.linspace(0, np.max(prob), 100)\n",
    "    cs = plt.contourf(xx, yy, probc.T, levels=levels, cmap=plt.cm.jet_r, extend='both')\n",
    "    plt.title(tmSet[imf])\n",
    "    cs.cmap.set_over('darkred')\n",
    "    plt.axis('off')\n",
    "    plt.pause(.1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('prob_'+figid+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c2ed19-89a6-4d1f-96dc-1532dbf300e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Plot probability flows ############\n",
    "plt.clf()\n",
    "plt.figure(figsize = (9, 9))\n",
    "plt.subplot(nRows_subplt, nCols_subplt, 1)\n",
    "plt.title('average')\n",
    "ax = plt.gca()\n",
    "\n",
    "for ic in range(n_clusters):\n",
    "    ax.arrow(clusters.clustercenters[ic, 0], clusters.clustercenters[ic, 1], dxsav[ic, 0], dxsav[ic, 1], \n",
    "             head_width=.2, linewidth=.5, color='white', alpha=1.0)\n",
    "\n",
    "plt.xlabel('UMAP 1')\n",
    "plt.ylabel('UMAP 2')\n",
    "plt.axis('off')\n",
    "\n",
    "for i in range(num_trajModSet):\n",
    "    indmodels = np.where(inds_tmSet_models == i)[0]\n",
    "    dxf = np.mean(dxs[indmodels, :, :], axis=0)\n",
    "    plt.subplot(nRows_subplt,nCols_subplt,i+2)\n",
    "    ax = plt.gca()\n",
    "    for ic in range(n_clusters):\n",
    "        ax.arrow(clusters.clustercenters[ic, 0], clusters.clustercenters[ic, 1], dxf[ic, 0], dxf[ic, 1], \n",
    "                 head_width=.2, linewidth=.5, color='white', alpha=1.0)\n",
    "    plt.xlabel('UMAP 1')\n",
    "    plt.ylabel('UMAP 2')\n",
    "    plt.axis('off')\n",
    "    plt.title(tmSet[i])\n",
    "    plt.pause(.1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('probflows_'+figid+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b809c65-850d-4297-96d2-6b34ef3a5abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "############### Plot speed, alpha, cell-cell align, and cell-cell contact #################\n",
    "vsetList = [Xpcat[:, -3], Xpcat[:, -2], Xpcat[:, -1], cb_ratio_traj]\n",
    "captionset = ['speed','alpha','cellcell_align','cellcell_contact']\n",
    "nbins = 20\n",
    "for iv in range(len(vsetList)):\n",
    "    vset = vsetList[iv]\n",
    "    indg = np.where(np.logical_and(np.logical_not(np.isnan(vset)), np.logical_not(np.isinf(vset))))[0]\n",
    "    plt.clf()\n",
    "    plt.figure(figsize = (9, 9))\n",
    "    plt.subplot(nRows_subplt, nCols_subplt, 1)\n",
    "    vdist1, xedges1, yedges1 = np.histogram2d(embedTraj_feat[indg, 0], embedTraj_feat[indg, 1],\n",
    "                                              bins=nbins, weights=vset[indg])\n",
    "    norm1, xedges1, yedges1 = np.histogram2d(embedTraj_feat[indg, 0], embedTraj_feat[indg, 1], \n",
    "                                             bins=[xedges1, yedges1])\n",
    "    vdist1 = np.divide(vdist1, norm1)\n",
    "    indnan = np.where(np.isnan(vdist1))\n",
    "    indgood = np.where(np.logical_and(np.logical_not(np.isnan(vdist1)), np.logical_not(np.isinf(vdist1))))\n",
    "    xedges1c = .5*(xedges1[1:] + xedges1[0:-1])\n",
    "    yedges1c = .5*(yedges1[1:] + yedges1[0:-1])\n",
    "    xx, yy = np.meshgrid(xedges1c, yedges1c)\n",
    "    levels = np.linspace(np.min(vdist1[indgood]), np.max(vdist1[indgood]), 20)\n",
    "    cs = plt.contourf(xx, yy, vdist1.T, cmap=plt.cm.jet, levels=levels)\n",
    "    plt.xlabel('UMAP 1')\n",
    "    plt.ylabel('UMAP 2')\n",
    "    for ic in range(n_clusters):\n",
    "        ax = plt.gca()\n",
    "        ax.arrow(clusters.clustercenters[ic, 0], clusters.clustercenters[ic, 1], dxsav[ic, 0], dxsav[ic, 1], \n",
    "                 head_width=.3, length_includes_head = True, width=.05, color='white', alpha=0.5)\n",
    "    cs.cmap.set_over('darkred')\n",
    "    cs.cmap.set_under('darkblue')\n",
    "    cbar = colorbar(cs)\n",
    "    cbar.set_label(captionset[iv])\n",
    "    #cbar.set_label('cell-cell boundary fraction')\n",
    "    #cbar.set_label('speed')\n",
    "    #cbar.set_label('beta')\n",
    "    plt.title('combined'+captionset[iv])\n",
    "    plt.axis('off')\n",
    "    plt.pause(3)\n",
    "    #plt.tight_layout()\n",
    "    #plt.savefig(captionset[iv]+'_flows_comb_'+figid+'.png')\n",
    "    #plt.subplot(4,3,12)\n",
    "    #cs = plt.contourf(xx,yy,vdist1.T,cmap=plt.cm.jet,levels=levels)\n",
    "    #cs.cmap.set_over('darkred')\n",
    "    #cs.cmap.set_under('darkblue')\n",
    "    #plt.axis('off'); plt.title('combined')\n",
    "    #plt.pause(.1)\n",
    "    for i in range(num_trajModSet):\n",
    "        plt.subplot(nRows_subplt, nCols_subplt, i + 2)\n",
    "        indstm = inds_conditions[i]\n",
    "        indstm = np.intersect1d(indg, indstm)\n",
    "        vdist1, xedges1, yedges1 = np.histogram2d(embedTraj_feat[indstm, 0], embedTraj_feat[indstm, 1], \n",
    "                                                  bins=nbins, weights=vset[indstm])\n",
    "        norm1, xedges1, yedges1 = np.histogram2d(embedTraj_feat[indstm, 0], embedTraj_feat[indstm, 1], \n",
    "                                                 bins=[xedges1, yedges1])\n",
    "        vdist1 = np.divide(vdist1, norm1)\n",
    "        indnan = np.where(np.isnan(vdist1))\n",
    "        indgood = np.where(np.logical_and(np.logical_not(np.isnan(vdist1)), np.logical_not(np.isinf(vdist1))))\n",
    "        cs = plt.contourf(xx, yy, vdist1.T, cmap=plt.cm.jet, levels=levels)\n",
    "        cs.cmap.set_over('darkred')\n",
    "        cs.cmap.set_under('darkblue')\n",
    "        plt.xlabel('UMAP 1')\n",
    "        plt.ylabel('UMAP 2')\n",
    "        plt.axis('off')\n",
    "        plt.title(tmSet[i])\n",
    "        plt.pause(.1)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(captionset[iv]+'_'+figid+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c3aeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# frames for time window\n",
    "fl = 72 # Lower frame number to start: 18 hrs\n",
    "fu = 120 # 30 hrs\n",
    "#fu = nframes  # Upper frame number to stop \n",
    "\n",
    "nbins = 100\n",
    "indstw = np.where(np.logical_and(indframes_traj < fu, indframes_traj > fl))[0]\n",
    "prob1, xedges1, yedges1 = np.histogram2d(embedTraj_feat[indstw, 0], embedTraj_feat[indstw, 1], \n",
    "                                         bins=nbins, density=True)\n",
    "prob1 = prob1/np.sum(prob1)\n",
    "prob1 = scipy.ndimage.gaussian_filter(prob1, sigma=2)\n",
    "xx, yy = np.meshgrid(.5*xedges1[1:]+.5*xedges1[0:-1], .5*yedges1[1:]+.5*yedges1[0:-1])\n",
    "probSet = [None]*num_trajModSet\n",
    "for imf in range(num_trajModSet):\n",
    "    indstm = inds_conditions[imf]\n",
    "    indstwm = np.intersect1d(indstm, indstw)\n",
    "    prob, xedges2, yedges2 = np.histogram2d(embedTraj_feat[indstwm, 0], embedTraj_feat[indstwm, 1], \n",
    "                                            bins=[xedges1, yedges1], density=True)\n",
    "    prob = scipy.ndimage.gaussian_filter(prob, sigma=2)\n",
    "    prob = prob/np.sum(prob)\n",
    "    probSet[imf] = prob.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbf2340-c5a5-4104-b259-93413b28eed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#*** Compute Transition matrix between micro-clusters & build Markov Model ***!\n",
    "centers_minima = clusters.clustercenters.copy()\n",
    "# Add assign attribute to find clusters' indices later\n",
    "clusters_minima = coor.clustering.AssignCenters(centers_minima, metric = 'euclidean')\n",
    "# Compute transition matrix between the cluster centers\n",
    "wctm.get_transition_matrix(x0set, x1set, clusters = clusters_minima)\n",
    "P = wctm.Mt.copy() # Copy Transition Matrix 'Mt' from wctm\n",
    "print(\"Shape of transition matrix before cleaning up =\", P.shape)\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.csgraph import connected_components\n",
    "\n",
    "graph = csr_matrix(P > 0.)\n",
    "n_components, labels = connected_components(csgraph=graph, directed=False, return_labels=True)\n",
    "unique, counts = np.unique(labels, return_counts=True)\n",
    "icc = unique[np.argmax(counts)]\n",
    "indcc = np.where(labels == icc)[0]\n",
    "\n",
    "centers_minima = centers_minima[indcc, :]\n",
    "clusters_minima = coor.clustering.AssignCenters(centers_minima, metric = 'euclidean')\n",
    "\n",
    "wctm.get_transition_matrix(x0set, x1set, clusters = clusters_minima)\n",
    "P = wctm.Mt.copy() # Transition Matrix\n",
    "print(\"Shape of transition matrix after removing disconnected micro-states =\", P.shape)\n",
    "\n",
    "# Generalized Perron-Cluster Cluster Analysis (GPCCA) to coarse-grain reversible and non-reversible MSMs\n",
    "import pygpcca as gp\n",
    "# copy original clustered single cell trajectories\n",
    "gpcca = gp.GPCCA(P, eta=None, z='LM', method='brandts')\n",
    "\n",
    "# Dump Transition Matrix for further analysis \n",
    "tmFileName = 'transitionMatrix_'+sysName+'_'+str(trajl)+'_'+date2day+'.joblib'\n",
    "with open(tmFileName, 'wb') as fp:\n",
    "    dump(P, fp, compress = 'zlib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14504ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "# Find Eigen Values and Eigen vectors of the transition matrix \"P\"\n",
    "H = .5*(P + np.transpose(P)) + .5j*(P - np.transpose(P))\n",
    "w, v = np.linalg.eig(H)  \n",
    "w = np.real(w)\n",
    "indsort = np.argsort(w)\n",
    "w = w[indsort] # Eigen Values\n",
    "v = v[:, indsort] # Eigen Vectors\n",
    "ncomp = 20 # Keep last \"ncomp\" eigen vectors\n",
    "vr = np.multiply(w[-ncomp:], np.real(v[:, -ncomp:]))\n",
    "vi = np.multiply(w[-ncomp:], np.imag(v[:, -ncomp:]))\n",
    "vkin = np.append(vr, vi, axis = 1)\n",
    "#plt.plot(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9529407a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kinetic_states(self, vkin, nstates_final, nstates_initial = None, pcut_final = .01,\n",
    "                       max_states = 20, cluster_ninit = 10):\n",
    "    if nstates_initial is None:\n",
    "        nstates_initial = nstates_final\n",
    "    nstates_good = 0\n",
    "    nstates = nstates_initial\n",
    "    while nstates_good < nstates_final and nstates < max_states:\n",
    "        clusters_v = KMeans(n_clusters = nstates, init = 'k-means++',\n",
    "                            n_init = cluster_ninit, max_iter = 1000, \n",
    "                            random_state = 0)\n",
    "        clusters_v.fit(vkin)\n",
    "        stateSet = clusters_v.labels_\n",
    "        state_probs = np.zeros(nstates)\n",
    "        statesc,counts = np.unique(stateSet, return_counts = True)\n",
    "        state_probs[statesc] = counts/np.sum(counts)\n",
    "        print(np.sort(state_probs))\n",
    "        nstates_good = np.sum(state_probs > pcut_final)\n",
    "        print('{} states initial, {} states final'.format(nstates, nstates_good))\n",
    "        print(nstates, \"Current states\", nstates_good, \"Good states\")\n",
    "        nstates = nstates + 1\n",
    "    pcut = np.sort(state_probs)[-(nstates_final)] #nstates\n",
    "    states_plow = np.where(state_probs < pcut)[0]\n",
    "    # Get rid of the states with probabilities less than 'pcut'\n",
    "    for i in states_plow:\n",
    "        indstate = np.where(stateSet == i)[0]\n",
    "        for imin in indstate:\n",
    "            dists = wctm.get_dmat(np.array([vkin[imin, :]]), vkin)[0] #closest in eigen space\n",
    "            dists[indstate] = np.inf\n",
    "            ireplace = np.argmin(dists)\n",
    "            stateSet[imin] = stateSet[ireplace]\n",
    "    slabels, counts = np.unique(stateSet, return_counts = True)\n",
    "    s = 0\n",
    "    stateSet_clean = np.zeros_like(stateSet)\n",
    "    for slabel in slabels:\n",
    "        indstate = np.where(stateSet == slabel)[0]\n",
    "        stateSet_clean[indstate] = s\n",
    "        s = s + 1\n",
    "    stateSet = stateSet_clean\n",
    "    if np.max(stateSet) > nstates_final:\n",
    "        print(f'returning {np.max(stateSet)} states, {nstates_final} requested')\n",
    "        print(\"returning \", np.max(stateSet),\" states\", nstates_final, \"requested\")\n",
    "        \n",
    "    return stateSet, nstates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67c1ac2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nstates_final = 7\n",
    "max_states = 10*nstates_final\n",
    "stateSet, nstates = get_kinetic_states(wctm, vkin, nstates_final,\n",
    "                                       nstates_initial = None, pcut_final = .025, \n",
    "                                       max_states = max_states, cluster_ninit = 10)\n",
    "stateCenters = clusters_minima.clustercenters\n",
    "# NOTE: pcut_final = 0.2 - 0.25 makes better homogeneous state space occupation,\n",
    "# though vary with nstates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7db4c3e-0d43-4374-80fe-66a90769e13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nstates = np.unique(stateSet).size\n",
    "n_states = nstates\n",
    "state_centers_minima = np.zeros((n_states, neigen))\n",
    "for i in range(n_states):\n",
    "    indstate = np.where(stateSet == i)[0]\n",
    "    state_centers_minima[i, :] = np.median(stateCenters[indstate, :], axis=0)\n",
    "\n",
    "#nbins = probSet[0].shape[0]\n",
    "nbins = 100\n",
    "state_labels = np.array(list(string.ascii_uppercase))[0:nstates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bffbfe5-af4c-471b-968e-eb5975c8e483",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_probs = np.zeros((num_trajModSet, n_states))\n",
    "fl = 72 # 18 hrs\n",
    "fu = 120 # 30 hrs\n",
    "#fu = nframes\n",
    "cell_states = clusters_minima\n",
    "indstw = np.where(np.logical_and(indframes_traj < fu, indframes_traj > fl))[0]\n",
    "for i in range(num_trajModSet):\n",
    "    indstm = inds_conditions[i]\n",
    "    indstwm = np.intersect1d(indstm, indstw)\n",
    "    #x0 = embedTraj_feat[indstwm, :]\n",
    "    x0 = Xpcat[indstwm, :]\n",
    "    indc0 = stateSet[clusters_minima.assign(x0)]\n",
    "    statesc, counts = np.unique(indc0, return_counts = True)\n",
    "    state_probs[i, statesc] = counts/np.sum(counts)\n",
    "\n",
    "state_order = np.arange(n_states).astype(int)\n",
    "\n",
    "plt.clf()\n",
    "plt.figure(figsize = (7, 7))\n",
    "plt.imshow(state_probs[:, state_order], cmap=plt.cm.gnuplot)\n",
    "cbar = plt.colorbar()\n",
    "cbar.set_label('state probabilities')\n",
    "\n",
    "# We want to show all ticks...\n",
    "ax = plt.gca()\n",
    "ax.set_yticks(np.arange(len(tmSet)))\n",
    "ax.set_xticks(np.arange(nstates))\n",
    "ax.set_xticklabels(np.array(state_labels)[state_order])\n",
    "ax.set_yticklabels(tmSet)\n",
    "\n",
    "# Rotate the tick labels and set their alignment.\n",
    "plt.setp(ax.get_xticklabels(), rotation=10, ha=\"right\", rotation_mode=\"anchor\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('stateprobs_'+figid+'_nS_'+str(nstates)+'.png')\n",
    "np.savetxt('stateprobs_'+figid+'_nS_'+str(nstates)+'.dat', state_probs[:, state_order])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da839c87-2f96-4e8d-ba23-b7ba2cd1d79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plt.figure(figsize = (7, 6))\n",
    "nbins = 100\n",
    "prob1, xedges1, yedges1 = np.histogram2d(embedTraj_feat[:, 0], embedTraj_feat[:, 1], bins=nbins, density=True)\n",
    "prob1 = scipy.ndimage.gaussian_filter(prob1, sigma=2)\n",
    "xx1, yy1 = np.meshgrid(.5*xedges1[1:]+.5*xedges1[0:-1], .5*yedges1[1:]+.5*yedges1[0:-1])\n",
    "pts = np.array([xx1.flatten(), yy1.flatten()]).T\n",
    "indpts = clusters_minima.assign(pts)\n",
    "states = stateSet[indpts]\n",
    "states = states[prob1.flatten() > np.min(prob1[prob1 > 0])]\n",
    "pts = pts[prob1.flatten() > np.min(prob1[prob1 > 0]), :]\n",
    "plt.contourf(xx1, yy1, prob1.T, cmap=plt.cm.gray_r, levels=20, alpha=.3)\n",
    "plt.scatter(pts[:, 0], pts[:, 1], s=10, c=states, cmap=plt.cm.jet, marker='.', alpha=0.5)\n",
    "plt.scatter(clusters_minima.clustercenters[:, 0], clusters_minima.clustercenters[:, 1],\n",
    "            s = 100, c = stateSet, cmap = plt.cm.jet)\n",
    "\n",
    "for istate in range(n_states):\n",
    "    plt.text(state_centers_minima[istate, 0], state_centers_minima[istate, 1], str(state_labels[istate]))\n",
    "\n",
    "plt.pause(.1)\n",
    "plt.tight_layout()\n",
    "plt.savefig('kineticstates_'+figid+'_nS_'+str(nstates)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9e41ab-9f5d-4795-a3fa-8497d31a2fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "states_x = stateSet[cell_states.assign(embedTraj_feat)]\n",
    "inds_states = [None]*n_states\n",
    "for i in range(n_states):\n",
    "    indstate = np.where(states_x == i)[0]\n",
    "    inds_states[i] = indstate\n",
    "\n",
    "vset = Xpcat[:, -3]\n",
    "\n",
    "plt.clf()\n",
    "plt.figure(figsize = (8, 7))\n",
    "ax = plt.gca()\n",
    "\n",
    "for i in range(n_states):\n",
    "    ii = state_order[i]\n",
    "    vplot = ax.violinplot(vset[inds_states[ii]], positions=[i+1], \n",
    "                          showmeans=True, showextrema=False) # quantiles=[.05,.95])\n",
    "    vplot['cmeans'].set_color('black')\n",
    "    for pc in vplot['bodies']:\n",
    "        pc.set_facecolor('black')\n",
    "        #pc.set_edgecolor('black')\n",
    "        #pc.set_alpha(1)\n",
    "    plt.pause(.1)\n",
    "\n",
    "ax.set_xticks(range(1, n_states + 1))\n",
    "ax.set_xticklabels(np.array(state_labels)[state_order])\n",
    "#plt.ylabel('log2(nuc/cyto cc-ratio)')\n",
    "#plt.ylabel(r'cell-cell local alignment $\\langle \\hat{v}_1 \\cdot \\hat{v}_2 \\rangle$')\n",
    "#plt.ylabel('speed (z-score)')\n",
    "plt.ylabel('speed (z-score)')\n",
    "plt.xlabel('states')\n",
    "plt.pause(.1)\n",
    "plt.tight_layout()\n",
    "plt.savefig('speed_'+figid+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4095b2-b493-45b7-9a1d-5a07c14f65e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from adjustText import adjust_text\n",
    "\n",
    "plt.clf()\n",
    "istate = 3\n",
    "indcells_traj = inds_states[istate]\n",
    "indmodels = indtreatment_traj[indcells_traj]\n",
    "indcells_model = cellinds1_traj[indcells_traj]\n",
    "#for ic in [50, 100, 150, 200]: # range(indcells_traj.size)\n",
    "for ic in range(0, indcells_traj.size, 50):\n",
    "    celltraj = self.get_cell_trajectory(indcells_model[ic])\n",
    "    self.visual = True\n",
    "    self.show_cells(celltraj)\n",
    "    plt.pause(1)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('cell'+str(ic)+'_state'+str(istate)+'_'+figid+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1786482",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "#from sklearn.metrics import silhouette_score\n",
    "nstates_initial = nstates_initial\n",
    "def get_kineticstates(self, nstates_initial, P = None, clusters_minima = None,\n",
    "                      pcut_final = 0.01, random_state = 0, ncomp = 15):\n",
    "    if P is None:\n",
    "        print('input transition matrix')\n",
    "        return\n",
    "    if clusters_minima is None:\n",
    "        clusters_minima = self.clusterst\n",
    "    stateCenters = clusters_minima.clustercenters\n",
    "    nstates_good = 0\n",
    "    nstates = nstates_initial\n",
    "    #silhouette_scores = []\n",
    "    #nClusters = []\n",
    "    #plt.clf()\n",
    "    #plt.figure(figsize = (6, 5))\n",
    "    while nstates_good < nstates_initial and nstates < 5*nstates_initial: \n",
    "        H = .5*(P + np.transpose(P)) + .5j*(P - np.transpose(P))\n",
    "        w, v = np.linalg.eig(H) # Find Eigen Values and Eigen vectors of transition matrix \n",
    "        w = np.real(w)\n",
    "        indsort = np.argsort(w)\n",
    "        w = w[indsort] # Eigen Values\n",
    "        v = v[:, indsort] # Eigen Vectors\n",
    "        vr = np.multiply(w[-ncomp:], np.real(v[:, -ncomp:]))\n",
    "        vi = np.multiply(w[-ncomp:], np.imag(v[:, -ncomp:]))\n",
    "        vkin = np.append(vr, vi, axis=1)\n",
    "        ############################ KMeans from deeptime #########################\n",
    "        #clusters_v = KMeans(n_clusters=nstates, init_strategy='kmeans++', max_iter=1000).fit(vkin).fetch_model()\n",
    "        #stateSet = clusters_v.transform(vkin)\n",
    "        ############################ KMeans from sklearn ##########################\n",
    "        clusters_v = KMeans(n_clusters = nstates, init = 'k-means++', n_init = 20000, max_iter = 1000)\n",
    "        clusters_v.fit(vkin)\n",
    "        stateSet = clusters_v.labels_\n",
    "        ######### Examine how many n_clusters aka nstates better represent ########\n",
    "        #labels_s = clusters_v.predict(vkin)\n",
    "        #score = silhouette_score(vkin, labels_s)\n",
    "        #silhouette_scores.append(score)\n",
    "        state_center_minima = np.zeros((nstates, neigen))\n",
    "        for i in range(nstates):\n",
    "            indstate = np.where(stateSet == i)[0]\n",
    "            state_center_minima[i, :] = np.mean(clusters_minima.clustercenters[indstate, :], axis=0)\n",
    "        state_probs = np.zeros((num_trajModSet, nstates))\n",
    "        for i in range(num_trajModSet):\n",
    "            indstm = inds_conditions[i]\n",
    "            #x0 = embedTraj_feat[indstm, :]\n",
    "            x0 = Xpcat[indstm, :]\n",
    "            indc0 = stateSet[clusters_minima.assign(x0)]\n",
    "            statesc, counts = np.unique(indc0, return_counts=True)\n",
    "            state_probs[i, statesc] = counts/np.sum(counts)\n",
    "        state_tprobs = np.sum(state_probs, axis=0)/num_trajModSet\n",
    "        print(\"Transition probabilities of\", nstates, \"states: \",np.sort(state_tprobs))\n",
    "        # nstates_good: If transition probabilities of cell states are higher than set probability cutoff\n",
    "        nstates_good = np.sum(state_tprobs > pcut_final)\n",
    "        print(nstates, \"initial states,\", nstates_good, \"final (Good) states\")\n",
    "        #nClusters.append(nstates)\n",
    "        nstates = nstates + 1\n",
    "    pcut = np.sort(state_tprobs)[-(nstates_initial)] # nstates\n",
    "    states_plow = np.where(state_tprobs < pcut)[0] # states with low probabilities\n",
    "    ################# Remove/clean states with low probabilities ####################\n",
    "    for i in states_plow:\n",
    "        indstate = np.where(stateSet == i)[0]\n",
    "        for imin in indstate:\n",
    "            dists = wctm.get_dmat(np.array([stateCenters[imin, :]]), stateCenters)[0]\n",
    "            dists[indstate] = np.inf\n",
    "            ireplace = np.argmin(dists)\n",
    "            stateSet[imin] = stateSet[ireplace]\n",
    "    slabels, counts = np.unique(stateSet, return_counts=True)\n",
    "    s = 0\n",
    "    stateSet_clean = np.zeros_like(stateSet)\n",
    "    for slabel in slabels:\n",
    "        indstate = np.where(stateSet == slabel)[0]\n",
    "        stateSet_clean[indstate] = s\n",
    "        s = s + 1\n",
    "    stateSet = stateSet_clean\n",
    "    \"\"\"\n",
    "    # Plot Silhouette Scores \n",
    "    plt.plot(nClusters, silhouette_scores)\n",
    "    plt.title('Silhouette Score')\n",
    "    plt.xlabel('Number of clusters')\n",
    "    plt.ylabel('Score')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('silhouette_scores_'+figid+'_'+str(nstates)+'.png') \n",
    "    \"\"\"\n",
    "    return stateSet, nstates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf4f12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_kstates = True\n",
    "stateCenters = clusters_minima.clustercenters\n",
    "\n",
    "if get_kstates:\n",
    "    stateSet, nstates = get_kineticstates(wctm, nstates_initial, P=P, \n",
    "                                          clusters_minima = clusters_minima, pcut_final=.02)\n",
    "    objFile = 'stateSet_'+figid+'_nS'+str(nstates)+'.joblib'\n",
    "    states_object = [clusters_minima, stateSet]\n",
    "    with open(objFile, 'wb') as fpStates:\n",
    "        dump(states_object, fpStates, compress = 'zlib')\n",
    "else:\n",
    "    objFile = 'stateSet_'+figid+'_nS'+str(nstates_initial)+'.joblib'\n",
    "    with open(objFile, 'rb') as fpStates:\n",
    "        states_object = load(fpStates)\n",
    "    clusters_minima = states_object[0]\n",
    "    stateSet = states_object[1]\n",
    "plt.close('all')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
