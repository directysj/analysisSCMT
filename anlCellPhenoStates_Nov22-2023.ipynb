{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa6aad1-2760-430e-a238-b9d5460bcd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys, os, time, math\n",
    "sys.path.append('/home/groups/ZuckermanLab/jalim/instalLocal/celltraj/celltraj')\n",
    "import jcTrajectory_CP as cellTraj\n",
    "import h5py\n",
    "import pickle\n",
    "import subprocess\n",
    "import umap\n",
    "import scipy\n",
    "from csaps import csaps\n",
    "import string\n",
    "from joblib import dump, load\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0dd855-6501-4587-9792-4b115833f95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "######### Parameters of transitions between \"macroscopic\" states ##########\n",
    "nstates_final = 7\n",
    "max_states = 100\n",
    "pcut_final = 0.094\n",
    "n_components_tMat = 15\n",
    "\n",
    "# Trajectory Length for morphodynamical trajectory analysis\n",
    "trajl = 40\n",
    "\n",
    "# Flag to import data of a certain wells combinations\n",
    "wells_flg = 2\n",
    "\n",
    "if(wells_flg == 0):\n",
    "  wellsInfo = 'Awells'\n",
    "  conditions = ['A1','A2','A3','A4','A5','C1','C2','C3'] # LIGANDS (CONDITIONS)\n",
    "  tmSet = ['OSM1','EGF1','EGF+TGFB1','TGFB1','PBS1','OSM+EGF+TGFB','OSM+EGF','OSM+TGFB']\n",
    "elif(wells_flg == 1):\n",
    "  wellsInfo = 'Bwells'\n",
    "  conditions = ['B1','B2','B3','B4','B5','C1','C2','C3'] # LIGANDS (CONDITIONS)\n",
    "  tmSet = ['OSM2','EGF2','EGF+TGFB2','TGFB2','PBS2','OSM+EGF+TGFB','OSM+EGF','OSM+TGFB']\n",
    "else:\n",
    "  wellsInfo = 'AllWells'\n",
    "  conditions = ['A1','A2','A3','A4','A5','B1','B2','B3','B4','B5','C1','C2','C3'] # LIGANDS (CONDITIONS)\n",
    "  tmSet = ['OSM1','EGF1','EGF+TGFB1','TGFB1','PBS1','OSM2','EGF2','EGF+TGFB2','TGFB2','PBS2','OSM+EGF+TGFB','OSM+EGF','OSM+TGFB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3532cbbb-a126-4de3-9f78-d2344abddf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "today = date.today()\n",
    "date2day = today.strftime(\"%b%d-%Y\")\n",
    "sysName = 'LI204601_P'\n",
    "figid = sysName+'_tlen'+str(trajl)+'_'+date2day\n",
    "\n",
    "# Indices for the ligands \n",
    "inds_tmSet = [i for i in range(nConditions)]\n",
    "inds_tmSet = np.array(inds_tmSet).astype(int)\n",
    "nfovs = 4\n",
    "fovs = [i for i in range(1, nfovs + 1)]\n",
    "fovs = np.array(fovs).astype(int)\n",
    "dateSet = ['']\n",
    "pathSet = ['/home/groups/ZuckermanLab/jalim/LI204601_INCUCYTE/segsCellPose/bayesianTrackTest/']\n",
    "imagingSet = [0 for i in range(nConditions)]\n",
    "modelList = [None]*(nfovs*(nConditions))\n",
    "modelList_conditions = np.zeros(nfovs*(nConditions)).astype(int)\n",
    "\n",
    "i = 0\n",
    "icond = 0\n",
    "for cond in conditions:\n",
    "    for fov in fovs:\n",
    "        modelList_conditions[i] = icond\n",
    "        modelList[i] = pathSet[imagingSet[icond]]+sysName+'_'+cond+'_'+str(fov)+dateSet[imagingSet[icond]]\n",
    "        #print(\"Models: \",modelList[i])\n",
    "        i = i + 1\n",
    "    icond = icond + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713e6436-1946-4430-812e-6dd339f57ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmodels = len(modelList)\n",
    "modelSet = [None]*nmodels\n",
    "indgood_models = np.array([]).astype(int)\n",
    "\n",
    "for i in range(nmodels):\n",
    "    try:\n",
    "        objFile = modelList[i]+'.obj'\n",
    "        objFileHandler = open(objFile,'rb')\n",
    "        modelSet[i] = pickle.load(objFileHandler)\n",
    "        print('loaded '+objFile+' with '+str(modelSet[i].cells_indSet.size)+' cells')\n",
    "        objFileHandler.close()\n",
    "        test = len(modelSet[i].linSet)\n",
    "        indgood_models = np.append(indgood_models,i)\n",
    "    except:\n",
    "        print(\"ERROR in reading *.obj files\")\n",
    "        sys.exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b4c9b3-bdf0-4dcd-8205-7c53c799dd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of frames (image snapshots) in one condition per FOVs\n",
    "nframes = 193 \n",
    "cellnumber_stdSet = np.ones(nmodels)*np.inf\n",
    "# range of frame indices where cell numbers are higher: ~70-98%\n",
    "sframe = 70.*nframes/100.; sframe = math.ceil(sframe)\n",
    "eframe = 98.5*nframes/100.; eframe = math.ceil(eframe)\n",
    "cellnumber_frames = np.arange(sframe, eframe).astype(int)\n",
    "cellnumber_std_cut = .50 # This was set to 0.10 by Jeremy \n",
    "frames = np.arange(nframes)\n",
    "# Abscissas at which smoothing will be done using CSAPS package\n",
    "abSmooth = np.linspace(frames[0], frames[-1], 10000)\n",
    "\n",
    "#plt.clf()\n",
    "#plt.figure(figsize = (8, 7))\n",
    "\n",
    "with open('cellNumbers.dat', 'w', encoding = 'utf-8') as fp: # PRINT cell numbers in a file for each model\n",
    "     for i in indgood_models:\n",
    "        ncells = np.zeros(nframes)\n",
    "        ncells_smooth = np.zeros_like(ncells)\n",
    "        for iS in range(nframes):\n",
    "           ncells[iS]=np.sum(modelSet[i].cells_frameSet==iS)\n",
    "           fp.write(str(ncells[iS])+\"\\t\")\n",
    "           fp.write(\"\\n\")\n",
    "        # Cubic Spline Approximation (CSAPS) to smoothen the data\n",
    "        splfov = csaps(frames, ncells/ncells[0], abSmooth, smooth = 0.98) # Scaled by ncells[0] to avoid large numbers\n",
    "        ncells_smooth = splfov*ncells[0] # smoothened cell numbers reverse scaled back to original\n",
    "        cellnumber_std = np.std(ncells[cellnumber_frames] - ncells_smooth[cellnumber_frames])/np.mean(ncells[cellnumber_frames])\n",
    "        cellnumber_stdSet[i] = cellnumber_std # Standard Deviation in Cell Numbers\n",
    "        #print(\"cellnumber_stdSet[\",i,\"] = \", cellnumber_std)\n",
    "        #plt.plot(ncells/ncells[0], color = colModels[i], label = capModels[i])\n",
    "        #plt.plot(ncells, color = colModels[i], label = capModels[i])\n",
    "        #plt.plot(ncells/ncells[0]); plt.pause(.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ecf6b7-2c52-40c5-bf22-43ce046bfcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "indhigh_std = np.where(cellnumber_stdSet > cellnumber_std_cut)[0]\n",
    "indgood_models = np.setdiff1d(indgood_models, indhigh_std)\n",
    "#indgood_models = np.setdiff1d(indgood_models, np.array([51]).astype(int)) #missing comdx for EGF0_4\n",
    "\n",
    "# get cell counts\n",
    "nf = len(tmSet)\n",
    "inds_tmSet_models = np.zeros(nmodels).astype(int)\n",
    "inds_imagingSet_models = np.zeros(nmodels).astype(int)\n",
    "i = 0\n",
    "icond = 0\n",
    "for cond in conditions:\n",
    "    for fov in fovs:\n",
    "        inds_tmSet_models[i] = inds_tmSet[icond]\n",
    "        inds_imagingSet_models[i] = imagingSet[icond]\n",
    "        i = i + 1\n",
    "    icond = icond + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d375e33e-9ac5-4ada-90c8-d926e1c5f2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in indgood_models:\n",
    "    if inds_imagingSet_models[i] == 0:\n",
    "        modelSet[i].Xf[np.isnan(modelSet[i].Xf)] = 0.0 #just replace with zeros for now? Not sure best...\n",
    "\n",
    "nfeat_com = 3\n",
    "Xf_com0 = np.zeros((0, nfeat_com))\n",
    "for i in indgood_models:\n",
    "    if inds_imagingSet_models[i] == 0:\n",
    "        Xf_com0 = np.append(Xf_com0,modelSet[i].Xf_com, axis = 0)\n",
    "\n",
    "av_dx = np.nanmean(Xf_com0[:, 0])\n",
    "std_dx = np.nanstd(Xf_com0[:, 0])\n",
    "for i in indgood_models:\n",
    "    modelSet[i].Xf_com[:, 0] = (modelSet[i].Xf_com[:, 0] - av_dx)/std_dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145ce0b4-0206-4dc8-95e5-85b8e5edbc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "wctm = cellTraj.Trajectory() # import Trajectory object \n",
    "\n",
    "nfeat = modelSet[indgood_models[0]].Xf.shape[1]\n",
    "Xf = np.zeros((0, nfeat))\n",
    "indtreatment = np.array([])\n",
    "indcellSet = np.array([])\n",
    "for i in indgood_models:\n",
    "    if inds_imagingSet_models[i] == 0:\n",
    "        Xf = np.append(Xf, modelSet[i].Xf, axis = 0)\n",
    "        indtreatment = np.append(indtreatment, i*np.ones(modelSet[i].Xf.shape[0]))\n",
    "        indcellSet = np.append(indcellSet, modelSet[i].cells_indSet)\n",
    "\n",
    "indtreatment = indtreatment.astype(int)\n",
    "indcellSet = indcellSet.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062daab5-7191-4e2a-be0f-296cc330c005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the sklearn package (intended for ease of use over performance/scalability)\n",
    "varCutOff = 10\n",
    "from sklearn.decomposition import PCA \n",
    "# n_components specifies the number of principal components to extract from the covariance matrix\n",
    "pca = PCA(n_components = varCutOff) \n",
    "pca.fit(Xf) # builds the covariance matrix and \"fits\" the principal components\n",
    "Xpca = pca.transform(Xf) # transforms the data into the pca representation\n",
    "nPCs = Xpca.shape[1]\n",
    "\n",
    "wctm.Xpca = Xpca\n",
    "wctm.pca = pca\n",
    "for i in indgood_models:\n",
    "    if inds_imagingSet_models[i] == 0:\n",
    "        indsf = np.where(indtreatment == i)[0]\n",
    "        modelSet[i].Xpca = Xpca[indsf, :]\n",
    "\n",
    "indgood_models = indgood_models[np.where(inds_imagingSet_models[indgood_models] == 0)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5039cd4-8f7c-40c4-a5ce-482f39a37b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "self = wctm\n",
    "wctm.trajl = trajl\n",
    "all_trajSet = [None]*nmodels\n",
    "for i in indgood_models:\n",
    "    modelSet[i].get_unique_trajectories()\n",
    "    all_trajSet[i] = modelSet[i].trajectories.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f41b2c-4ac1-456b-bd22-a7cb4c06d776",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xpcat = np.zeros((0, pca.n_components_*trajl + nfeat_com*trajl))\n",
    "indtreatment_traj = np.array([])\n",
    "indstack_traj = np.array([])\n",
    "indframes_traj = np.array([])\n",
    "cellinds0_traj = np.array([])\n",
    "cellinds1_traj = np.array([])\n",
    "#cc_ratio_traj = np.array([])\n",
    "cb_ratio_traj = np.array([])\n",
    "for i in indgood_models:\n",
    "    print('building trajectory data for model {}...'.format(i))\n",
    "    modelSet[i].trajectories = all_trajSet[i].copy()\n",
    "    modelSet[i].trajl = trajl\n",
    "    modelSet[i].traj = modelSet[i].get_traj_segments(trajl)\n",
    "    data = modelSet[i].Xpca[modelSet[i].traj, :]\n",
    "    datacom = modelSet[i].Xf_com[modelSet[i].traj, :]\n",
    "    data = data.reshape(modelSet[i].traj.shape[0], modelSet[i].Xpca.shape[1]*trajl)\n",
    "    datacom = datacom.reshape(modelSet[i].traj.shape[0], modelSet[i].Xf_com.shape[1]*trajl)\n",
    "    data = np.append(data, datacom, axis = 1)\n",
    "    indgood = np.where(np.sum(np.isnan(data), axis = 1) == 0)[0]\n",
    "    data = data[indgood, :]\n",
    "    modelSet[i].traj = modelSet[i].traj[indgood, :]\n",
    "    Xpcat = np.append(Xpcat, data, axis = 0)\n",
    "    indtreatment_traj = np.append(indtreatment_traj, i*np.ones(data.shape[0]))\n",
    "    indstacks = modelSet[i].cells_imgfileSet[modelSet[i].traj[:, 0]]\n",
    "    indstack_traj = np.append(indstack_traj, indstacks)\n",
    "    indframes = modelSet[i].cells_frameSet[modelSet[i].traj[:, 0]]\n",
    "    indframes_traj = np.append(indframes_traj, indframes)\n",
    "    cellinds0 = modelSet[i].traj[:, 0]\n",
    "    cellinds0_traj = np.append(cellinds0_traj, cellinds0)\n",
    "    cellinds1 = modelSet[i].traj[:, -1]\n",
    "    # cc_ratio = modelSet[i].cc_ratio[cellinds1]\n",
    "    # cc_ratio_traj = np.append(cc_ratio_traj, cc_ratio)\n",
    "    cellinds1_traj = np.append(cellinds1_traj, cellinds1)\n",
    "    cb_ratio_traj = np.append(cb_ratio_traj, modelSet[i].Xf[cellinds1, 77])\n",
    "\n",
    "cellinds0_traj = cellinds0_traj.astype(int)\n",
    "cellinds1_traj = cellinds1_traj.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47caf44a-9f1a-46dd-a8cc-9968ca47c66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_embedding = True\n",
    "neigen_umap = 2\n",
    "if get_embedding:\n",
    "    reducer = umap.UMAP(n_neighbors=200, min_dist=0.1, n_components=neigen_umap, metric='euclidean')\n",
    "    trans = reducer.fit(Xpcat)\n",
    "    x = trans.embedding_\n",
    "    indst = np.arange(x.shape[0]).astype(int)\n",
    "    wctm.Xtraj = x.copy()\n",
    "    wctm.indst = indst.copy()\n",
    "    #dump(x, sysName+'_trajl'+str(trajl)+'_d2embedding_'+date2day+'.joblib')\n",
    "else:\n",
    "    #x=load(sysName+'_trajl'+str(trajl)+'_d2embedding_'+date2day+'.joblib')\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c086337e-d340-4a1d-9c8b-5712003f28a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#neigen = x.shape[1]\n",
    "neigen = Xpcat.shape[1] # If embedded trajectories aren't UMAP'ed \n",
    "\n",
    "inds_conditions = [None]*nf\n",
    "for imf in range(nf):\n",
    "    indmodels = np.intersect1d(indgood_models, np.where(inds_tmSet_models == imf)[0])\n",
    "    indstm = np.array([])\n",
    "    for imodel in indmodels:\n",
    "        indtm = np.where(indtreatment_traj == imodel)\n",
    "        indstm = np.append(indstm, indtm)\n",
    "    inds_conditions[imf] = indstm.astype(int).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779bbbbf-d431-4d6e-ad96-fc87b7caf016",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Cluster single-cell trajectories of a given snippet length by using KMeans from deeptime \n",
    "from deeptime.clustering import KMeans\n",
    "n_clusters = 200\n",
    "model = KMeans(n_clusters = n_clusters,  # place 100 cluster centers\n",
    "               init_strategy = 'kmeans++',  # kmeans++ initialization strategy\n",
    "               max_iter = 0,  # don't actually perform the optimization, just place centers\n",
    "               fixed_seed = 13)\n",
    "################################ Initial clustering ###############################\n",
    "clustering = model.fit(Xpcat).fetch_model() # If embedded trajectories aren't UMAP'ed \n",
    "#clustering = model.fit(x).fetch_model()\n",
    "\n",
    "model.initial_centers = clustering.cluster_centers\n",
    "model.max_iter = 5000\n",
    "clusters = model.fit(Xpcat).fetch_model() # If embedded trajectories aren't UMAP'ed \n",
    "#clusters = model.fit(x).fetch_model()\n",
    "wctm.clusterst = clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85f77ec-5f90-4e8a-a3fc-73b37aec4b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = 50\n",
    "for i in indgood_models:\n",
    "    modelSet[i].trajectories = all_trajSet[i].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6387381e-2856-48c9-8878-1cb31d469e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trajectory_steps(self, inds=None, traj=None, Xtraj=None,\n",
    "                         get_trajectories=True, nlag=1): #traj and Xtraj should be indexed same\n",
    "    if inds is None:\n",
    "        inds = np.arange(self.cells_indSet.size).astype(int)\n",
    "    if get_trajectories:\n",
    "        self.get_unique_trajectories(cell_inds=inds)\n",
    "    if traj is None:\n",
    "        traj = self.traj\n",
    "    if Xtraj is None:\n",
    "        x = self.Xtraj\n",
    "    else:\n",
    "        x = Xtraj\n",
    "    trajp1 = self.get_traj_segments(self.trajl + nlag)\n",
    "    inds_nlag = np.flipud(np.arange(self.trajl + nlag - 1, -1, -nlag)).astype(int) #keep indices every nlag\n",
    "    trajp1 = trajp1[:, inds_nlag]\n",
    "    ntraj = trajp1.shape[0]\n",
    "    #neigen = x.shape[1]\n",
    "    neigen = Xpcat.shape[1]\n",
    "    x0 = np.zeros((0, neigen))\n",
    "    x1 = np.zeros((0, neigen))\n",
    "    inds_trajp1 = np.zeros((0, 2)).astype(int)\n",
    "    for itraj in range(ntraj):\n",
    "        test0 = trajp1[itraj, 0:-1]\n",
    "        test1 = trajp1[itraj, 1:]\n",
    "        res0 = (traj[:, None] == test0[np.newaxis, :]).all(-1).any(-1)\n",
    "        res1 = (traj[:, None] == test1[np.newaxis, :]).all(-1).any(-1)\n",
    "        if np.sum(res0) == 1 and np.sum(res1) == 1:\n",
    "            indt0 = np.where(res0)[0][0]\n",
    "            indt1 = np.where(res1)[0][0]\n",
    "            #x0 = np.append(x0, np.array([x[indt0, :]]), axis=0)\n",
    "            #x1 = np.append(x1, np.array([x[indt1, :]]), axis=0)\n",
    "            x0 = np.append(x0, np.array([Xpcat[indt0, :]]), axis=0)\n",
    "            x1 = np.append(x1, np.array([Xpcat[indt1, :]]), axis=0)\n",
    "            inds_trajp1 = np.append(inds_trajp1, np.array([[indt0, indt1]]), axis=0)\n",
    "        if itraj%100 == 0:\n",
    "            sys.stdout.write('matching up trajectory '+str(itraj)+'\\n')\n",
    "    self.Xtraj0 = x0\n",
    "    self.Xtraj1 = x1\n",
    "    self.inds_trajp1 = inds_trajp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a7614c-022d-42ef-9dbc-f479f8d509d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dxs = np.zeros((nmodels, n_clusters, neigen))\n",
    "x0set = np.zeros((0, neigen))\n",
    "x1set = np.zeros((0, neigen))\n",
    "inds_trajsteps_models = np.array([]).astype(int)\n",
    "for i in indgood_models:\n",
    "    print('getting flows from model: '+str(i))\n",
    "    indstm = np.where(indtreatment_traj == i)[0]\n",
    "    if indstm.size > 0:\n",
    "        #modelSet[i].Xtraj = x[indstm, 0:neigen]\n",
    "        modelSet[i].Xtraj = Xpcat[indstm, 0:neigen]\n",
    "        indstm_model = indstm - np.min(indstm) #index in model\n",
    "        if inds_imagingSet_models[i] == 1:\n",
    "            modelSet[i].get_trajectory_steps(inds=None, get_trajectories=False, traj=modelSet[i].traj[indstm_model, :],\n",
    "                                             Xtraj=modelSet[i].Xtraj[indstm_model, :])\n",
    "        else:\n",
    "            get_trajectory_steps(modelSet[i], inds=None, get_trajectories=False, traj=modelSet[i].traj[indstm_model, :], \n",
    "                                 Xtraj=modelSet[i].Xtraj[indstm_model, :])\n",
    "        x0 = modelSet[i].Xtraj0\n",
    "        x1 = modelSet[i].Xtraj1\n",
    "        x0set = np.append(x0set, x0, axis=0)\n",
    "        x1set = np.append(x1set, x1, axis=0)\n",
    "        inds_trajsteps_models = np.append(inds_trajsteps_models, np.ones(x0.shape[0])*i)\n",
    "        dx = x1 - x0\n",
    "        for iclust in range(n_clusters):\n",
    "            xc = np.array([clusters.cluster_centers[iclust, :]])\n",
    "            dmatr = wctm.get_dmat(modelSet[i].Xtraj[modelSet[i].inds_trajp1[:, -1], :],\n",
    "                                  xc) #get closest cells to cluster center\n",
    "            indr = np.argsort(dmatr[:, 0])\n",
    "            indr = indr[0:knn]\n",
    "            cellindsr = modelSet[i].traj[[modelSet[i].inds_trajp1[indr, -1]], -1]\n",
    "            dxs[i, iclust, :] = np.mean(dx[indr, :], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f36293-90e2-4cf4-8360-feb0d164a55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cdist2d(prob1):\n",
    "    nx = prob1.shape[0]; ny = prob1.shape[1]\n",
    "    prob1 = prob1/np.sum(prob1)\n",
    "    prob1 = prob1.flatten()\n",
    "    indprob1 = np.argsort(prob1)\n",
    "    probc1 = np.zeros_like(prob1)\n",
    "    probc1[indprob1] = np.cumsum(prob1[indprob1])\n",
    "    probc1 = 1. - probc1\n",
    "    probc1 = probc1.reshape((nx, ny))\n",
    "    return probc1\n",
    "\n",
    "def colorbar(mappable):\n",
    "    from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "    last_axes = plt.gca()\n",
    "    ax = mappable.axes\n",
    "    fig = ax.figure\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "    cbar = fig.colorbar(mappable, cax=cax)\n",
    "    plt.sca(last_axes)\n",
    "    return cbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3240bc31-42f6-4b06-8f63-2494d9334863",
   "metadata": {},
   "outputs": [],
   "source": [
    "indtreatment_traj = indtreatment_traj.astype(int)\n",
    "inds_imagingSet_traj = inds_imagingSet_models[indtreatment_traj]\n",
    "\n",
    "dxsav = np.mean(dxs, axis=0)\n",
    "#x[np.isnan(x)]=0.0 #Seriously...\n",
    "\n",
    "nbins = 20\n",
    "#frames for a time window\n",
    "#fl = 0\n",
    "#fu = nframes \n",
    "fl = 72\n",
    "fu = 120\n",
    "\n",
    "plt.clf()\n",
    "plt.figure(figsize = (9, 9))\n",
    "indstw = np.where(np.logical_and(indframes_traj < fu, indframes_traj > fl))[0]\n",
    "indscc = np.where(cb_ratio_traj < np.inf)[0]\n",
    "indstw = np.intersect1d(indstw, indscc)\n",
    "#indstw=np.intersect1d(indstw,np.where(inds_imagingSet_traj==1)[0])\n",
    "probSet = [None]*nmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3d0b10-dcfc-403d-bfe1-0c706321fa18",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(5, 3, 1)\n",
    "prob1,xedges1,yedges1 = np.histogram2d(x[indstw, 0], x[indstw, 1], bins=nbins, density=True)\n",
    "prob1c = get_cdist2d(prob1)\n",
    "xx,yy = np.meshgrid(.5*xedges1[1:] + .5*xedges1[0:-1], .5*yedges1[1:] + .5*yedges1[0:-1])\n",
    "levels = np.linspace(0, 1, 21)\n",
    "cs = plt.contourf(xx, yy, prob1c.T, levels=levels, cmap=plt.cm.jet_r)\n",
    "cbar = colorbar(cs)\n",
    "#cbar.set_label('cumulative probability')\n",
    "plt.title('combined cumulative distribution')\n",
    "plt.axis('off')\n",
    "for imf in range(nf):\n",
    "    tm = tmSet[imf]\n",
    "    indstm = inds_conditions[imf]\n",
    "    indstwm = np.intersect1d(indstm, indstw)\n",
    "    indstwm = np.intersect1d(indstwm, indscc)\n",
    "    prob,xedges2,yedges2 = np.histogram2d(x[indstwm, 0], x[indstwm, 1], \n",
    "                                          bins=[xedges1, yedges1], density=True)\n",
    "    #prob = prob/np.sum(prob)\n",
    "    probc = get_cdist2d(prob)\n",
    "    probSet[imf] = prob.copy()\n",
    "    plt.subplot(5, 3, imf+2)\n",
    "    #levels = np.linspace(0,np.max(prob),100)\n",
    "    cs = plt.contourf(xx, yy, probc.T, levels=levels, cmap=plt.cm.jet_r, extend='both')\n",
    "    plt.title(tmSet[imf])\n",
    "    cs.cmap.set_over('darkred')\n",
    "    plt.axis('off')\n",
    "    plt.pause(.1)\n",
    "\n",
    "plt.savefig('prob_'+figid+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cdb22c-a208-4b4b-9b4c-c4303171c7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plt.figure(figsize=(9,9))\n",
    "plt.subplot(5,3,1)\n",
    "plt.title('average')\n",
    "plt.axis('off')\n",
    "for ic in range(n_clusters):\n",
    "    ax=plt.gca()\n",
    "    ax.arrow(clusters.clustercenters[ic,0], clusters.clustercenters[ic,1],\n",
    "             dxsav[ic,0],dxsav[ic,1],head_width=.2,linewidth=.5,color='white',alpha=1.0)\n",
    "\n",
    "for i in range(nf):\n",
    "    indmodels=np.where(inds_tmSet_models==i)[0]\n",
    "    dxf=np.mean(dxs[indmodels,:,:],axis=0)\n",
    "    plt.subplot(5,3,i+2)\n",
    "    ax=plt.gca()\n",
    "    for ic in range(n_clusters):\n",
    "        ax.arrow(clusters.clustercenters[ic,0], clusters.clustercenters[ic,1],\n",
    "                 dxf[ic,0],dxf[ic,1],head_width=.2,linewidth=.5,color='white',alpha=1.0)\n",
    "    plt.xlabel('UMAP 1')\n",
    "    plt.ylabel('UMAP 2')\n",
    "    plt.axis('off')\n",
    "    plt.title(tmSet[i])\n",
    "    plt.pause(.1)\n",
    "\n",
    "plt.savefig('probflows_'+figid+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbcca4a-613b-45d6-b098-c5ce101d7874",
   "metadata": {},
   "outputs": [],
   "source": [
    "vsetList = [Xpcat[:, -3], Xpcat[:, -2], Xpcat[:, -1], cb_ratio_traj]\n",
    "captionset = ['speed', 'alpha', 'cellcell_align', 'cellcell_contact']\n",
    "#vset = cb_ratio_traj\n",
    "#vset = cc_ratio_traj\n",
    "#vset = Xpcat[:, -3]\n",
    "nf = len(tmSet)\n",
    "nbins = 20\n",
    "for iv in range(len(vsetList)):\n",
    "    vset = vsetList[iv]\n",
    "    indg = np.where(np.logical_and(np.logical_not(np.isnan(vset)), np.logical_not(np.isinf(vset))))[0]\n",
    "    plt.clf()\n",
    "    plt.figure(figsize = (9, 9))\n",
    "    plt.subplot(5, 3, 1)\n",
    "    vdist1,xedges1,yedges1 = np.histogram2d(x[indg, 0], x[indg, 1], bins=nbins, weights=vset[indg])\n",
    "    norm1,xedges1,yedges1 = np.histogram2d(x[indg, 0], x[indg, 1], bins=[xedges1, yedges1])\n",
    "    vdist1 = np.divide(vdist1, norm1)\n",
    "    indnan = np.where(np.isnan(vdist1))\n",
    "    indgood = np.where(np.logical_and(np.logical_not(np.isnan(vdist1)), np.logical_not(np.isinf(vdist1))))\n",
    "    xedges1c = .5*(xedges1[1:] + xedges1[0:-1])\n",
    "    yedges1c = .5*(yedges1[1:] + yedges1[0:-1])\n",
    "    xx,yy = np.meshgrid(xedges1c, yedges1c)\n",
    "    #vdist1 = np.log(vdist1)\n",
    "    levels = np.linspace(np.min(vdist1[indgood]), np.max(vdist1[indgood]), 20)\n",
    "    #levels = np.linspace(0, np.max(vdist1[indgood]), 20)\n",
    "    cs = plt.contourf(xx, yy, vdist1.T, cmap=plt.cm.jet, levels=levels)\n",
    "    for ic in range(n_clusters):\n",
    "        ax = plt.gca()\n",
    "        ax.arrow(clusters.clustercenters[ic, 0], clusters.clustercenters[ic, 1], dxsav[ic,0], dxsav[ic,1],\n",
    "                 head_width=.2, linewidth=.5, color='white', alpha=1.0)\n",
    "    cs.cmap.set_over('darkred')\n",
    "    cs.cmap.set_under('darkblue')\n",
    "    cbar = colorbar(cs)\n",
    "    cbar.set_label(captionset[iv])\n",
    "    #cbar.set_label('cell-cell boundary fraction')\n",
    "    #cbar.set_label('speed')\n",
    "    #cbar.set_label('beta')\n",
    "    plt.title('combined'+captionset[iv])\n",
    "    plt.axis('off')\n",
    "    plt.pause(3)\n",
    "    #plt.savefig(captionset[iv]+'_flows_comb_'+figid+'.png')\n",
    "    #plt.subplot(4,3,12)\n",
    "    #cs=plt.contourf(xx,yy,vdist1.T,cmap=plt.cm.jet,levels=levels)\n",
    "    #cs.cmap.set_over('darkred')\n",
    "    #cs.cmap.set_under('darkblue')\n",
    "    #plt.axis('off'); plt.title('combined')\n",
    "    #plt.pause(.1)\n",
    "    for i in range(nf-1):\n",
    "        plt.subplot(5, 3, i+2)\n",
    "        indstm = inds_conditions[i]\n",
    "        indstm = np.intersect1d(indg, indstm)\n",
    "        vdist1,xedges1,yedges1 = np.histogram2d(x[indstm, 0], x[indstm, 1], \n",
    "                                                bins=nbins, weights=vset[indstm])\n",
    "        norm1,xedges1,yedges1 = np.histogram2d(x[indstm, 0], x[indstm, 1], \n",
    "                                               bins=[xedges1, yedges1])\n",
    "        vdist1 = np.divide(vdist1, norm1)\n",
    "        indnan = np.where(np.isnan(vdist1))\n",
    "        indgood = np.where(np.logical_and(np.logical_not(np.isnan(vdist1)), np.logical_not(np.isinf(vdist1))))\n",
    "        cs = plt.contourf(xx, yy, vdist1.T, cmap=plt.cm.jet, levels=levels)\n",
    "        cs.cmap.set_over('darkred')\n",
    "        cs.cmap.set_under('darkblue')\n",
    "        #plt.xlabel('UMAP 1')\n",
    "        #plt.ylabel('UMAP 2')\n",
    "        plt.axis('off')\n",
    "        plt.title(tmSet[i])\n",
    "        plt.pause(.1)\n",
    "    plt.savefig(captionset[iv]+'_'+figid+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837c5a6d-654c-4092-98d6-b34c8387eedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#frames for time window\n",
    "#fl = 0\n",
    "#fu = nframes \n",
    "fl = 72\n",
    "fu = 120\n",
    "\n",
    "nbins = 100\n",
    "indstw = np.where(np.logical_and(indframes_traj < fu, indframes_traj > fl))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d888c8f4-d21f-430d-8799-d48438fb524c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob1,xedges1,yedges1 = np.histogram2d(x[indstw, 0], x[indstw, 1], bins=nbins, density=True)\n",
    "prob1 = prob1/np.sum(prob1)\n",
    "prob1 = scipy.ndimage.gaussian_filter(prob1, sigma=2)\n",
    "xx,yy = np.meshgrid(.5*xedges1[1:] + .5*xedges1[0:-1], .5*yedges1[1:] + .5*yedges1[0:-1])\n",
    "probSet = [None]*nf\n",
    "for imf in range(nf):\n",
    "    indstm = inds_conditions[imf]\n",
    "    indstwm = np.intersect1d(indstm,indstw)\n",
    "    prob,xedges2,yedges2 = np.histogram2d(x[indstwm, 0], x[indstwm, 1],\n",
    "                                          bins=[xedges1, yedges1], density=True)\n",
    "    prob = scipy.ndimage.gaussian_filter(prob, sigma=2)\n",
    "    prob = prob/np.sum(prob)\n",
    "    probSet[imf] = prob.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ab1013-e173-4b22-be80-5b87741b6830",
   "metadata": {},
   "outputs": [],
   "source": [
    "################# Markov State Models: Generate transition matrix #################\n",
    "centers_minima  = clusters.cluster_centers.copy()\n",
    "nclusters = clusters.cluster_centers.shape[0]\n",
    "\n",
    "# Assign \"new data\" to cluster centers\n",
    "indc0 = clusters.transform(x0set).astype(int)\n",
    "indc1 = clusters.transform(x1set).astype(int)\n",
    "wctm.get_transitionMatrixDeeptime(indc0, indc1, nclusters)\n",
    "P = wctm.Mt.copy()\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.csgraph import connected_components\n",
    "graph = csr_matrix(P > 0.)\n",
    "n_components, labels = connected_components(csgraph=graph, directed=False, return_labels=True)\n",
    "unique, counts = np.unique(labels, return_counts=True)\n",
    "icc = unique[np.argmax(counts)]\n",
    "indcc = np.where(labels == icc)[0]\n",
    "centers_minima = centers_minima[indcc, :]\n",
    "\n",
    "############### Using pyEmma for assignments only #################\n",
    "import pyemma.coordinates as coor\n",
    "clusters_minima = coor.clustering.AssignCenters(centers_minima, metric='euclidean')\n",
    "#### Now clusters_minima will have attribute clusters_minima.clustercenters\n",
    "nclusters = clusters_minima.clustercenters.shape[0]\n",
    "indc0 = clusters_minima.assign(x0set)\n",
    "indc1 = clusters_minima.assign(x1set)\n",
    "wctm.get_transitionMatrixDeeptime(indc0, indc1, nclusters)\n",
    "P = wctm.Mt.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4aa626e-6240-431c-8d0b-16f9a348d87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygpcca as gp\n",
    "gpcca = gp.GPCCA(P, eta=None, z='LM', method='brandts')\n",
    "\n",
    "# Dump Transition Matrix for further analysis \n",
    "tmFileName = 'tMat_'+sysName+'_'+str(trajl)+'_'+date2day+'pc'+str(nPCs)+'u'+str(neigen_umap)+wellsInfo+'.joblib'\n",
    "with open(tmFileName, 'wb') as fp:\n",
    "     dump(P, fp, compress = 'zlib')\n",
    "\n",
    "# Find Eigen Values and Eigen vectors of the transition matrix \"P\"\n",
    "H = .5*(P + np.transpose(P)) + .5j*(P - np.transpose(P))\n",
    "w, v = np.linalg.eig(H)  \n",
    "w = np.real(w)\n",
    "indsort = np.argsort(w)\n",
    "w = w[indsort] # Eigen Values\n",
    "v = v[:, indsort] # Eigen Vectors\n",
    "ncomp = n_components_tMat # Keep last \"ncomp\" eigen vectors\n",
    "vr = np.multiply(w[-ncomp:], np.real(v[:, -ncomp:]))\n",
    "vi = np.multiply(w[-ncomp:], np.imag(v[:, -ncomp:]))\n",
    "vkin = np.append(vr, vi, axis = 1)\n",
    "#plt.plot(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769f466f-9318-4f9e-813a-7e0363302e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "################### Get kinetics of cell (macro) state transitions #####################\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def get_kinetic_states_module(self, vkin, nstates_final, nstates_initial = None, pcut_final = .01,\n",
    "                              max_states = 20, cluster_ninit = 10):\n",
    "       nstates_good = 0\n",
    "       nstates = nstates_initial\n",
    "       vkinFit = vkin\n",
    "       while nstates <= max_states:\n",
    "            clusters_v = KMeans(n_clusters = nstates, init = 'k-means++',\n",
    "                                n_init = cluster_ninit, max_iter = 5000, \n",
    "                                random_state = 0)\n",
    "            clusters_v.fit(vkinFit) \n",
    "            stateSet = clusters_v.labels_\n",
    "            state_probs = np.zeros(nstates)\n",
    "            statesc,counts = np.unique(stateSet, return_counts = True)\n",
    "            state_probs[statesc] = counts/np.sum(counts)\n",
    "            print(np.sort(state_probs))\n",
    "            nstates_good = np.sum(state_probs > pcut_final)\n",
    "            print('{} states initial, {} states final'.format(nstates, nstates_good))\n",
    "            print(nstates, \"Current states\", nstates_good, \"Good states\")\n",
    "            nstates = nstates + 1\n",
    "            if nstates_good >= nstates_final:\n",
    "               break\n",
    "       pcut = np.sort(state_probs)[-(nstates_final)] #nstates\n",
    "       states_plow = np.where(state_probs < pcut)[0]\n",
    "       # Assign (micro)states to existing state centers aka macrostates with probabilities less than 'pcut'\n",
    "       for i in states_plow:\n",
    "           indstate = np.where(stateSet == i)[0]\n",
    "           for imin in indstate:\n",
    "               dists = wctm.get_dmat(np.array([vkinFit[imin, :]]), vkinFit)[0] #closest in eigen space\n",
    "               dists[indstate] = np.inf\n",
    "               ireplace = np.argmin(dists)\n",
    "               stateSet[imin] = stateSet[ireplace]\n",
    "       slabels, counts = np.unique(stateSet, return_counts = True)\n",
    "       s = 0\n",
    "       stateSet_clean = np.zeros_like(stateSet)\n",
    "       for slabel in slabels:\n",
    "           indstate = np.where(stateSet == slabel)[0]\n",
    "           stateSet_clean[indstate] = s\n",
    "           s = s + 1\n",
    "       stateSet = stateSet_clean\n",
    "       if np.max(stateSet) > nstates_final:\n",
    "          print(\"returning \", np.max(stateSet),\" states\", nstates_final, \"requested\")\n",
    "       return stateSet, nstates_good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b39722b-2779-47ce-bf59-590998def526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module to optimize pcut_final that shows best clustering onto 7 states \n",
    "def get_kinetic_states(self, vkin, nstates_final, nstates_initial = None, pcut_final = .01,\n",
    "                       max_states = 20, cluster_ninit = 10):\n",
    "       if nstates_initial is None:\n",
    "          nstates_initial = nstates_final\n",
    "       nstates_good = 0\n",
    "       while nstates_good < nstates_final or nstates_good > nstates_final:\n",
    "          stateSet, nstates_good = get_kinetic_states_module(wctm, vkin, nstates_final, \n",
    "                                                                      nstates_initial = nstates_initial, \n",
    "                                                                      pcut_final = pcut_final,\n",
    "                                                                      max_states = max_states,\n",
    "                                                                      cluster_ninit = cluster_ninit)\n",
    "          print(\"pcut_final = \",pcut_final)\n",
    "          pcut_final = pcut_final - 0.001 \n",
    "\n",
    "       return stateSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab20e20-47e1-4bc8-955f-c1ae0b97f85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_kstates = True\n",
    "stateCenters = clusters_minima.clustercenters\n",
    "if get_kstates:\n",
    "   stateSet = get_kinetic_states(wctm, vkin, nstates_final,\n",
    "                                 nstates_initial = None, pcut_final = pcut_final, \n",
    "                                 max_states = max_states, cluster_ninit = 10)\n",
    "   nstates = np.unique(stateSet).size\n",
    "   objFile = 'stateSet_'+figid+'_nS'+str(nstates)+'.joblib'\n",
    "   states_object = [clusters_minima, stateSet]\n",
    "   with open(objFile, 'wb') as fpStates:\n",
    "      dump(states_object, fpStates, compress = 'zlib')\n",
    "else:\n",
    "   objFile = 'stateSet_'+figid+'_nS'+str(nstates_initial)+'.joblib'\n",
    "   with open(objFile, 'rb') as fpStates:\n",
    "       states_object = load(fpStates)\n",
    "   clusters_minima = states_object[0]\n",
    "   stateSet = states_object[1]\n",
    "   nstates = np.unique(stateSet).size\n",
    "\n",
    "n_states = nstates\n",
    "state_centers_minima = np.zeros((n_states, neigen))\n",
    "for i in range(n_states):\n",
    "    indstate = np.where(stateSet == i)[0]\n",
    "    state_centers_minima[i, :] = np.median(stateCenters[indstate, :], axis=0)\n",
    "\n",
    "state_labels = np.array(list(string.ascii_uppercase))[0:nstates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38737baf-08fd-43f0-b60c-72307181d949",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbins = probSet[0].shape[0]\n",
    "plt.close('all')\n",
    "plt.clf()\n",
    "plt.figure(figsize = (6, 5))\n",
    "prob1,xedges1,yedges1 = np.histogram2d(x[:, 0], x[:, 1], bins=nbins, density=True)\n",
    "prob1 = scipy.ndimage.gaussian_filter(prob1, sigma=2)\n",
    "xx1,yy1 = np.meshgrid(.5*xedges1[1:] + .5*xedges1[0:-1], .5*yedges1[1:] + .5*yedges1[0:-1])\n",
    "pts = np.array([xx1.flatten(), yy1.flatten()]).T\n",
    "indpts = clusters_minima.assign(pts)\n",
    "states = stateSet[indpts]\n",
    "states = states[prob1.flatten() > np.min(prob1[prob1 > 0])]\n",
    "pts = pts[prob1.flatten() > np.min(prob1[prob1 > 0]), :]\n",
    "plt.contourf(xx1, yy1, prob1.T, cmap=plt.cm.gray_r, levels=20, alpha=.3)\n",
    "plt.scatter(pts[:,0], pts[:,1], s=10, c=states, cmap=plt.cm.jet, marker='.', alpha=0.5)\n",
    "plt.scatter(clusters_minima.clustercenters[:, 0], clusters_minima.clustercenters[:, 1],\n",
    "            s=100, c=stateSet, cmap=plt.cm.jet)\n",
    "\n",
    "for istate in range(n_states):\n",
    "    plt.text(state_centers_minima[istate, 0], state_centers_minima[istate, 1], str(state_labels[istate]))\n",
    "\n",
    "plt.pause(.1)\n",
    "plt.savefig('kineticstates_'+figid+'_nS_'+str(nstates)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73751f1-21ab-4e0e-ae0c-37c3798e9fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_probs = np.zeros((nf, n_states))\n",
    "fl = 72\n",
    "fu = 120\n",
    "#fu = nframes\n",
    "cell_states = clusters_minima\n",
    "indstw = np.where(np.logical_and(indframes_traj < fu, indframes_traj > fl))[0]\n",
    "for i in range(nf):\n",
    "    indstm = inds_conditions[i]\n",
    "    indstwm = np.intersect1d(indstm, indstw)\n",
    "    #x0 = x[indstwm, :]\n",
    "    x0 = Xpcat[indstwm, :]\n",
    "    indc0 = stateSet[clusters_minima.assign(x0)]\n",
    "    statesc,counts = np.unique(indc0, return_counts=True)\n",
    "    state_probs[i, statesc] = counts/np.sum(counts)\n",
    "\n",
    "state_order = np.arange(n_states).astype(int)\n",
    "plt.clf()\n",
    "plt.imshow(state_probs[:, state_order], cmap=plt.cm.gnuplot)\n",
    "cbar = plt.colorbar()\n",
    "cbar.set_label('state probabilities')\n",
    "# We want to show all ticks...\n",
    "ax = plt.gca()\n",
    "ax.set_yticks(np.arange(len(tmSet)))\n",
    "ax.set_xticks(np.arange(nstates))\n",
    "ax.set_xticklabels(np.array(state_labels)[state_order])\n",
    "ax.set_yticklabels(tmSet)\n",
    "# Rotate the tick labels and set their alignment.\n",
    "plt.setp(ax.get_xticklabels(), rotation=10, ha=\"right\",rotation_mode=\"anchor\")\n",
    "plt.pause(.1);\n",
    "\n",
    "plt.savefig('stProbs_'+figid+'_nS'+str(nstates)+'pc'+str(nPCs)+'u'+str(neigen_umap)+wellsInfo+'.png')\n",
    "np.savetxt('stProbs_'+figid+'_nS'+str(nstates)+'pc'+str(nPCs)+'u'+str(neigen_umap)+wellsInfo+'.dat', state_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1801876d-32d8-4c79-b608-ee354b54da51",
   "metadata": {},
   "outputs": [],
   "source": [
    "states_x = stateSet[cell_states.assign(x)]\n",
    "inds_states = [None]*n_states\n",
    "for i in range(n_states):\n",
    "    indstate = np.where(states_x == i)[0]\n",
    "    inds_states[i] = indstate\n",
    "\n",
    "vset = Xpcat[:, -3]\n",
    "plt.clf()\n",
    "ax = plt.gca()\n",
    "#vset = np.log2(cc_ratio_traj)\n",
    "for i in range(n_states):\n",
    "    ii = state_order[i]\n",
    "    vplot = ax.violinplot(vset[inds_states[ii]], positions=[i+1],\n",
    "                          showmeans=True, showextrema=False) #,quantiles=[.05,.95])\n",
    "    vplot['cmeans'].set_color('black')\n",
    "    for pc in vplot['bodies']:\n",
    "        pc.set_facecolor('black')\n",
    "        #pc.set_edgecolor('black')\n",
    "        #pc.set_alpha(1)\n",
    "    plt.pause(.1)\n",
    "\n",
    "ax.set_xticks(range(1, n_states+1))\n",
    "ax.set_xticklabels(np.array(state_labels)[state_order])\n",
    "#plt.ylabel('log2(nuc/cyto cc-ratio)')\n",
    "#plt.ylabel(r'cell-cell local alignment $\\langle \\hat{v}_1 \\cdot \\hat{v}_2 \\rangle$')\n",
    "#plt.ylabel('speed (z-score)')\n",
    "plt.ylabel('speed (z-score)')\n",
    "plt.xlabel('states')\n",
    "plt.pause(.1)\n",
    "plt.savefig('speed_'+figid+'.png')\n",
    "\n",
    "from adjustText import adjust_text\n",
    "\n",
    "istate=5\n",
    "indcells_traj=inds_states[istate]\n",
    "indmodels=indtreatment_traj[indcells_traj]\n",
    "indcells_model=cellinds1_traj[indcells_traj]\n",
    "for ic in [100,500,1000,1500,2000]: #range(indcells_traj.size):\n",
    "    model_sctm=modelSet[indgood_models[indmodels[ic]]]\n",
    "    celltraj=model_sctm.get_cell_trajectory(indcells_model[ic])\n",
    "    model_sctm.visual=True\n",
    "    model_sctm.show_cells(celltraj)\n",
    "    plt.pause(1)\n",
    "    plt.savefig('cell'+str(ic)+'_state'+str(istate)+'_'+figid+'.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
